{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a9147bea-bcb9-4244-97f9-514e63185e57",
   "metadata": {},
   "outputs": [],
   "source": [
    "#172.18.0.4\n",
    "import pyspark\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.types import StructType, StructField, IntegerType, StringType, DoubleType\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f06a0ee2-b840-4052-a045-903190dcc0ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "CATALOG_URI = \"http://nessie:19120/api/v1\"  # Nessie Server URI\n",
    "WAREHOUSE = \"s3://warehouse/\"               # Minio Address to Write to\n",
    "STORAGE_URI = \"http://172.18.0.4:9000\"     # Minio IP address from docker inspect\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "5fc715ed-c2b6-4ba2-acd8-a25d2442e221",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "spark.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0eaf47da-74a7-4f76-a4c4-3c99dd6acc6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "conf = (\n",
    "    pyspark.SparkConf()\n",
    "        .setAppName('billing')\n",
    "    \n",
    "    # .set(\"spark.executor.instances\", \"3\")  # 3 Executors\n",
    "    # .set(\"spark.executor.cores\", \"3\")  # 3 Cores per executor\n",
    "    # .set(\"spark.executor.memory\", \"3g\")  # 3GB RAM per executor\n",
    "    # .set(\"spark.driver.memory\", \"4g\")  # Ensure driver has enough memory\n",
    "    # .set(\"spark.sql.shuffle.partitions\", \"200\")  # Tune for large joins\n",
    "    # .set(\"spark.default.parallelism\", \"9\")  # Optimize parallel processing\n",
    "    # .set(\"spark.executor.instances\", \"3\")  # 3 Executors\n",
    "    # .set(\"spark.executor.cores\", \"2\")  # 3 Cores per executor\n",
    "    # .set(\"spark.executor.memory\", \"6g\")  # 3GB RAM per executor\n",
    "    # .set(\"spark.driver.memory\", \"6g\")  # Ensure driver has enough memory\n",
    "    # .set(\"spark.sql.shuffle.partitions\", \"200\")  # Tune for large joins\n",
    "    # .set(\"spark.default.parallelism\", \"200\")  # Optimize parallel processing\n",
    "    # .set(\"spark.memory.fraction\", \"0.7\")  #\n",
    "    # .set(\"spark.executor.memoryOverhead\", \"1024\") \n",
    "#     .set(\"spark.dynamicAllocation.enabled\", \"true\")\n",
    "# .set(\"spark.shuffle.service.enabled\", \"true\")\n",
    "        .set(\"spark.sql.debug.maxToStringFields\", \"100000\")\n",
    "        .set('spark.jars', '/opt/spark/workjars/iceberg-spark-runtime-3.5_2.12-1.5.0.jar,/opt/spark/workjars/nessie-spark-extensions-3.5_2.12-0.77.1.jar,/opt/spark/workjars/bundle-2.24.8.jar,/opt/spark/workjars/url-connection-client-2.24.8.jar')\n",
    "        .set('spark.sql.extensions', 'org.apache.iceberg.spark.extensions.IcebergSparkSessionExtensions,org.projectnessie.spark.extensions.NessieSparkSessionExtensions')\n",
    "        .set('spark.sql.catalog.nessie', 'org.apache.iceberg.spark.SparkCatalog')\n",
    "        .set('spark.sql.catalog.nessie.uri', CATALOG_URI)\n",
    "        .set('spark.sql.catalog.nessie.ref', 'main')\n",
    "        .set('spark.sql.catalog.nessie.authentication.type', 'NONE')\n",
    "        .set('spark.sql.catalog.nessie.catalog-impl', 'org.apache.iceberg.nessie.NessieCatalog')\n",
    "        .set('spark.sql.catalog.nessie.s3.endpoint', STORAGE_URI)\n",
    "        .set('spark.sql.catalog.nessie.warehouse', WAREHOUSE)\n",
    "        .set('spark.sql.catalog.nessie.io-impl', 'org.apache.iceberg.aws.s3.S3FileIO')\n",
    "        .set(\"spark.executor.memory\", \"2g\")\n",
    "        .set(\"spark.driver.memory\", \"2g\")\n",
    "        .set(\"spark.executor.memoryOverhead\", \"512m\")\n",
    "        .set(\"spark.sql.shuffle.partitions\", \"64\")\n",
    "        .set(\"spark.shuffle.spill\", \"true\")\n",
    "        .set(\"spark.shuffle.memoryFraction\", \"0.4\")\n",
    "#         .set(\"spark.executor.instances\", \"2\")  # Use 2 executors\n",
    "#         .set(\"spark.executor.cores\", \"2\")  # 2 cores per executor\n",
    "#         .set(\"spark.executor.memory\", \"5g\")  # 5GB per executor (10GB total)\n",
    "#         .set(\"spark.driver.memory\", \"2g\")  # 2GB for the driver\n",
    "#         .set(\"spark.memory.fraction\", \"0.6\")  # Lower memory fraction to leave room for overhead\n",
    "#         .set(\"spark.executor.memoryOverhead\", \"1g\")  # 1GB overhead per executor\n",
    "#         .set(\"spark.sql.shuffle.partitions\", \"100\")  # Adjust based on data size\n",
    "#         .set(\"spark.default.parallelism\", \"100\")  # Adjust parallelism\n",
    "#         .set(\"spark.dynamicAllocation.enabled\", \"true\")  # Enable dynamic allocation\n",
    "#         .set(\"spark.shuffle.service.enabled\", \"true\")  # Required for dynamic allocation\n",
    "#         .set(\"spark.sql.debug.maxToStringFields\", \"100000\")\n",
    "#         .set('spark.jars', '/opt/spark/workjars/iceberg-spark-runtime-3.5_2.12-1.5.0.jar,/opt/spark/workjars/nessie-spark-extensions-3.5_2.12-0.77.1.jar,/opt/spark/workjars/bundle-2.24.8.jar,/opt/spark/workjars/url-connection-client-2.24.8.jar')\n",
    "#         .set('spark.sql.extensions', 'org.apache.iceberg.spark.extensions.IcebergSparkSessionExtensions,org.projectnessie.spark.extensions.NessieSparkSessionExtensions')\n",
    "#         .set('spark.sql.catalog.nessie', 'org.apache.iceberg.spark.SparkCatalog')\n",
    "#         .set('spark.sql.catalog.nessie.uri', CATALOG_URI)\n",
    "#         .set('spark.sql.catalog.nessie.ref', 'main')\n",
    "#         .set('spark.sql.catalog.nessie.authentication.type', 'NONE')\n",
    "#         .set('spark.sql.catalog.nessie.catalog-impl', 'org.apache.iceberg.nessie.NessieCatalog')\n",
    "#         .set('spark.sql.catalog.nessie.s3.endpoint', STORAGE_URI)\n",
    "#         .set('spark.sql.catalog.nessie.warehouse', WAREHOUSE)\n",
    "#         .set('spark.sql.catalog.nessie.io-impl', 'org.apache.iceberg.aws.s3.S3FileIO')\n",
    "#     .set(\"spark.shuffle.service.enabled\", \"true\")  # Enable external shuffle service\n",
    "# .set(\"spark.shuffle.service.port\", \"7337\")  # Default shuffle service port\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3a1da920-e676-4759-b5f3-05e633e89f53",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "25/03/23 12:17:27 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n",
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "25/03/23 12:17:30 WARN Utils: Service 'SparkUI' could not bind on port 4040. Attempting port 4041.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Spark Session Started\n"
     ]
    }
   ],
   "source": [
    "spark = SparkSession.builder.master(\"local[*]\").config(conf=conf).getOrCreate()\n",
    "print(\"Spark Session Started\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "4d5e86c9-16e1-4997-b9a0-850642396e34",
   "metadata": {},
   "outputs": [],
   "source": [
    "result = spark.sql(\"SHOW TABLES IN nessie\").collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c899b723-0415-486b-8a1a-07573440b17f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(namespace='EnergyConsumptionFeederwise', tableName='EnergyConsumptionFeederwise_data_raw', isTemporary=False),\n",
       " Row(namespace='ageing', tableName='ageing_data_raw', isTemporary=False),\n",
       " Row(namespace='billing', tableName='billing_data_raw', isTemporary=False),\n",
       " Row(namespace='crm', tableName='crm_data_raw', isTemporary=False),\n",
       " Row(namespace='fact_billing_and_recovery', tableName='fact_billing_and_recovery_data_raw', isTemporary=False),\n",
       " Row(namespace='fact_billing_and_recovery2', tableName='fact_billing_and_recovery_data_raw', isTemporary=False),\n",
       " Row(namespace='fact_billing_and_recovery3', tableName='fact_billing_and_recovery_data_raw', isTemporary=False),\n",
       " Row(namespace='fact_billing_and_recovery4', tableName='fact_billing_and_recovery_data_raw', isTemporary=False),\n",
       " Row(namespace='fact_billing_and_recovery5', tableName='fact_billing_and_recovery_data_raw', isTemporary=False),\n",
       " Row(namespace='fact_billing_and_recovery_final1', tableName='fact_billing_and_recovery_data_raw', isTemporary=False),\n",
       " Row(namespace='fact_network_and_loss', tableName='fact_network_and_loss_data_raw', isTemporary=False),\n",
       " Row(namespace='fact_network_and_loss2', tableName='fact_network_and_loss_data_raw', isTemporary=False),\n",
       " Row(namespace='fault_tickets', tableName='fault_tickets_data_raw', isTemporary=False),\n",
       " Row(namespace='feedermaster', tableName='feedermaster_data_raw', isTemporary=False),\n",
       " Row(namespace='feedervoltage', tableName='feedervoltage_data_raw', isTemporary=False),\n",
       " Row(namespace='oms', tableName='oms_data_raw', isTemporary=False),\n",
       " Row(namespace='pmtmaster', tableName='pmtmaster_data_raw', isTemporary=False),\n",
       " Row(namespace='power_report', tableName='power_report_data_raw', isTemporary=False),\n",
       " Row(namespace='recovery', tableName='recovery_data_raw', isTemporary=False),\n",
       " Row(namespace='test', tableName='test_data_raw', isTemporary=False)]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "423a96e6-c33b-44c2-8e4d-34052329a05d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "no\n"
     ]
    }
   ],
   "source": [
    "for a in results:\n",
    "    \n",
    "if 'test' in [namespace for namespace in result]:\n",
    "    print(\"yes\")\n",
    "else:\n",
    "    print(\"no\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "96a06d68-b528-405e-8060-aaf5a12113f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No Iceberg packages found\n",
      "org.apache.iceberg.spark.SparkCatalog\n"
     ]
    }
   ],
   "source": [
    "print(spark.conf.get(\"spark.jars.packages\", \"No Iceberg packages found\"))\n",
    "print(spark.conf.get(\"spark.sql.catalog.nessie\", \"No Nessie catalog found\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c53f3ccc-d246-4aac-b2c5-85ae5fa22df5",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7a947119-4c34-4fd3-b7fc-ebc246206305",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "25/02/22 12:58:24 WARN SparkSession: Using an existing Spark session; only runtime SQL configurations will take effect.\n"
     ]
    }
   ],
   "source": [
    "# spark = SparkSession.builder.master(\"spark://spark:7077\").getOrCreate()\n",
    "from pyspark.sql import SparkSession\n",
    "\n",
    "spark = SparkSession.builder \\\n",
    "    .appName(\"TestExecutors\") \\\n",
    "    .master(\"spark://spark:7077\") \\\n",
    "    .config(\"spark.executor.instances\", \"2\") \\\n",
    "    .config(\"spark.executor.cores\", \"2\") \\\n",
    "    .config(\"spark.executor.memory\", \"2g\") \\\n",
    "    .getOrCreate()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d71a1521-a923-414d-a8e9-ab2d927c0d0f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cluster Info:\n",
      "  - Executors: 1\n",
      "  - Cores per executor: 12\n",
      "  - Executor Memory: Not Set\n"
     ]
    }
   ],
   "source": [
    "\n",
    "num_executors = spark._jsc.sc().getExecutorMemoryStatus().size() - 1  # Exclude driver\n",
    "\n",
    "# Get number of cores per executor\n",
    "num_cores = spark.sparkContext.defaultParallelism\n",
    "\n",
    "# Get memory per executor\n",
    "executor_memory = spark.conf.get(\"spark.executor.memory\", \"Not Set\")\n",
    "\n",
    "print(f\"Cluster Info:\")\n",
    "print(f\"  - Executors: {num_executors}\")\n",
    "print(f\"  - Cores per executor: {num_cores}\")\n",
    "print(f\"  - Executor Memory: {executor_memory}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c70209ad-d3bb-4e8a-bf36-639c813ca81d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12\n"
     ]
    }
   ],
   "source": [
    "df = spark.range(1000).rdd.getNumPartitions()\n",
    "print(df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "id": "5019e826-df73-4450-83c9-6a3399fb6512",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Map(034b7b88bc5d:37659 -> (455501414,455501414))\n"
     ]
    }
   ],
   "source": [
    "print(spark._jsc.sc().getExecutorMemoryStatus())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e478688e-efc7-40fc-b0c3-206203ce9f0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark = SparkSession.builder \\\n",
    "    .appName(\"TestApp\") \\\n",
    "    .config(\"spark.jars.packages\", \"org.apache.iceberg:iceberg-spark-runtime-3.5_2.12:1.5.0,org.projectnessie.nessie-integrations:nessie-spark-extensions-3.5_2.12:0.77.1,software.amazon.awssdk:bundle:2.24.8,software.amazon.awssdk:url-connection-client:2.24.8\") \\\n",
    "    .getOrCreate()\n",
    "print(\"Spark Session Started\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8cee0990-2792-4509-b889-7427376c61d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[0m\u001b[01;32mAgeing_202301.csv\u001b[0m*\n"
     ]
    }
   ],
   "source": [
    "ls \"/mnt/HabibData/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "6b527e85-3bc9-4cd6-b88a-cb31d9638c59",
   "metadata": {},
   "outputs": [],
   "source": [
    "csv = \"/mnt/HabibData/Ageing_202303.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "6bba51ad-dd14-4ca4-baef-89b5d63c9c01",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "\n",
    "# Read the CSV file into a DataFrame\n",
    "df = spark.read \\\n",
    "    .option(\"delimiter\", \"|\") \\\n",
    "    .option(\"header\", \"true\") \\\n",
    "    .option(\"inferSchema\", \"true\") \\\n",
    "    .csv(csv)\n",
    "\n",
    "# df.show()\n",
    "# df.printSchema()\n",
    "df = df.repartition(200)  # Match shuffle partitions\n",
    "# spark = SparkSession.builder.config(conf=conf).getOrCreate()\n",
    "# print(\"Spark Session Started\")\n",
    "df.writeTo(\"nessie.ageing.ageing_data_raw\").createOrReplace()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "bdcd9510-012c-468d-ae18-778121400223",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.repartition(200)  # Match shuffle partitions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5d204f7-9ac1-42b9-9d26-3ad56b9a0e87",
   "metadata": {},
   "source": [
    "OMS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "bb92784b-b51b-491f-b520-be15791c3f9c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "++\n",
      "||\n",
      "++\n",
      "++\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# spark.sql(\"DROP table nessie.oms.oms_data_raw\").show()\n",
    "# spark.sql(\"DROP schema nessie.oms\").show()\n",
    "spark.sql(\"CREATE NAMESPACE nessie.oms\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "8597d158-840d-4a6a-90dd-323b86de78c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "csv = \"/mnt/HabibData/filtered_fault_data.csv\"\n",
    "df = spark.read \\\n",
    "    .option(\"header\", \"true\") \\\n",
    "    .option(\"inferSchema\", \"true\") \\\n",
    "    .csv(csv)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "1323d81f-fec8-4fa7-85b0-5ba8fc973374",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+-------------------+----------+-----+-----+-------------------+-------------+-------------------+---------------+------+--------------+---------+-----+-----------+--------------+---+--------+------+--------------------+----------+-------+-------+----+---+--------+------+----------+-----------+----------+----+---------+--------+---------+-------+----------------+----------+----------+--------------+-----------+-------+----------+\n",
      "|Createdon |punchCloseAt       |OutageType|saifi|saidi|consumer_count_fdr5|outageSubType|initialoffreason   |htclosingreason|fdr_Id|fdr_name      |grid_name|Relay|isemergency|israintripping|TAT|duration|dts_Id|consumer_count_fdr18|datetime  |tempmax|tempmin|temp|dew|humidity|precip|precipprob|precipcover|preciptype|snow|snowdepth|windgust|windspeed|winddir|sealevelpressure|cloudcover|visibility|solarradiation|solarenergy|uvindex|severerisk|\n",
      "+----------+-------------------+----------+-----+-----+-------------------+-------------+-------------------+---------------+------+--------------+---------+-----+-----------+--------------+---+--------+------+--------------------+----------+-------+-------+----+---+--------+------+----------+-----------+----------+----+---------+--------+---------+-------+----------------+----------+----------+--------------+-----------+-------+----------+\n",
      "|2023-01-01|2023-01-01 01:45:52|DTS       |NULL |NULL |NULL               |DTS Off      |Voltage Fluctuation|NULL           |3146  |GALLANT SUMMIT|NULL     |NULL |NULL       |NO            |96 |01:36:06|529533|NULL                |2023-01-01|28.0   |11.0   |19.0|8.6|57.3    |0.0   |0         |0.0        |NULL      |0   |0        |25.9    |20.5     |238.4  |1019.0          |0.0       |4.2       |185.0         |16.1       |7      |10        |\n",
      "+----------+-------------------+----------+-----+-----+-------------------+-------------+-------------------+---------------+------+--------------+---------+-----+-----------+--------------+---+--------+------+--------------------+----------+-------+-------+----+---+--------+------+----------+-----------+----------+----+---------+--------+---------+-------+----------------+----------+----------+--------------+-----------+-------+----------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "25/02/27 17:52:06 WARN CSVHeaderChecker: CSV header does not conform to the schema.\n",
      " Header: Createdon, punchCloseAt, OutageType, saifi, saidi, consumer_count_fdr, outageSubType, initialoffreason, htclosingreason, fdr_Id, fdr_name, grid_name, Relay, isemergency, israintripping, TAT, duration, dts_Id, consumer_count_fdr, datetime, tempmax, tempmin, temp, dew, humidity, precip, precipprob, precipcover, preciptype, snow, snowdepth, windgust, windspeed, winddir, sealevelpressure, cloudcover, visibility, solarradiation, solarenergy, uvindex, severerisk\n",
      " Schema: Createdon, punchCloseAt, OutageType, saifi, saidi, consumer_count_fdr5, outageSubType, initialoffreason, htclosingreason, fdr_Id, fdr_name, grid_name, Relay, isemergency, israintripping, TAT, duration, dts_Id, consumer_count_fdr18, datetime, tempmax, tempmin, temp, dew, humidity, precip, precipprob, precipcover, preciptype, snow, snowdepth, windgust, windspeed, winddir, sealevelpressure, cloudcover, visibility, solarradiation, solarenergy, uvindex, severerisk\n",
      "Expected: consumer_count_fdr5 but found: consumer_count_fdr\n",
      "CSV file: file:///mnt/HabibData/filtered_fault_data.csv\n"
     ]
    }
   ],
   "source": [
    "# df.select('Time').limit(1).show()\n",
    "df.limit(1).show(truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "752c69b5-d9e6-4638-a7ae-0729093f20d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "25/02/27 17:53:56 WARN CSVHeaderChecker: CSV header does not conform to the schema.\n",
      " Header: Createdon, punchCloseAt, OutageType, saifi, saidi, consumer_count_fdr, outageSubType, initialoffreason, htclosingreason, fdr_Id, fdr_name, grid_name, Relay, isemergency, israintripping, TAT, duration, dts_Id, consumer_count_fdr, datetime, tempmax, tempmin, temp, dew, humidity, precip, precipprob, precipcover, preciptype, snow, snowdepth, windgust, windspeed, winddir, sealevelpressure, cloudcover, visibility, solarradiation, solarenergy, uvindex, severerisk\n",
      " Schema: Createdon, punchCloseAt, OutageType, saifi, saidi, consumer_count_fdr5, outageSubType, initialoffreason, htclosingreason, fdr_Id, fdr_name, grid_name, Relay, isemergency, israintripping, TAT, duration, dts_Id, consumer_count_fdr18, datetime, tempmax, tempmin, temp, dew, humidity, precip, precipprob, precipcover, preciptype, snow, snowdepth, windgust, windspeed, winddir, sealevelpressure, cloudcover, visibility, solarradiation, solarenergy, uvindex, severerisk\n",
      "Expected: consumer_count_fdr5 but found: consumer_count_fdr\n",
      "CSV file: file:///mnt/HabibData/filtered_fault_data.csv\n",
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "# spark = SparkSession.builder.config(conf=conf).getOrCreate()\n",
    "# print(\"Spark Session Started\")\n",
    "df.writeTo(\"nessie.oms.oms_data_raw\").createOrReplace()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "631a8de1-8cbf-40c5-abb2-8fa9f1c0fda6",
   "metadata": {},
   "source": [
    "CRM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "9ba317fb-2da4-467c-8ea6-8619a9a8a2e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "csv = \"/mnt/HabibData/CRM_202301-202501.csv\"\n",
    "df = spark.read \\\n",
    "    .option(\"header\", \"true\") \\\n",
    "    .option(\"inferSchema\", \"true\") \\\n",
    "    .csv(csv)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae974472-1cb4-4695-8cd0-6d7efed9a23d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# spark.sql(\"DROP table nessie.crm.crm_data_raw\").show()\n",
    "# spark.sql(\"DROP schema nessie.crm\").show()\n",
    "spark.sql(\"CREATE NAMESPACE nessie.crm\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b9fd6f63-ea58-41d1-9970-552f2822af2b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+--------+----------------+---------------------+-------------------+---------------+----------------+--------+------------+-------------+-------------+-------------+------+---+-------+----+-----+------+----------------+----------------+----------------------+---------------+-----------+---+------+---------+-------+---------------+--------------+------+------------+--------------+------------+------------------------------+------+----------------+--------------+-------------------+-------------------+------------+------------------+------------+--------------+------------------+---------------+-------------------+-----------------------+--------------+----------------+-----------------------+------+-----------------+-------------------+------------+----------+--------------------------+---------------+------------------+------------+--------+------+-----------+------------+------------+-------------+-------------+--------------+-------------+--------------+------------+-------------+-----------------+------------------+---------------+----------------+------------+-------------+----------------+-----------------+-------------+-------------+--------------+---------+--------------+----------------+------------+---------+---------+-----------+-------+----------+-----------+--------+---------------------+------------------+-----------+--------------------+--------------+----------------------+---------------+--------------+-----------+------------------+---------+-----------+-------+-------+-------+--------+---------+---------+---------+---------+---------+---------+---------+---------+---------+---------+---------+---------+---------+---------+---------+---------+---------+---------+-----------+-----------+-----------+-----------+-----------+-----------+-----------+-----------+-----------+-----------+---------+---------+---------+---------+---------+---------+---------+---------+---------+---------+---------+----------+--------+--------------+------------+-------------------+-----------------+----------------------+--------------------+\n",
      "|AccountContract     |Key Date|Business Partner|Legacy Account Number|Legacy Move In Date|Consumer Number|Contract Account|Contract|Move-In Date|Move-Out Date|Billing Class|Rate Category|Region|IBC|IBCName|PIBC|DCIBC|DC OIP|DC Rate Category|CA Creation Date|Contract Creation Date|ConsumerCounter|Postal Code|OIP|Phase |Cycle Day|MRU    |Sanctioned Load|Connected Load|Status|Last DC Date|Last DC Reason|Premise Type|Customer Name                 |PMT   |Set Aside Amount|Set Aside Code|Installement Number|Installement Amount|PSC Location|PSC Classification|PSC Ministry|PSC Department|PSC Sub-Department|Schedule Number|PSC Consumer Region|Strategic/Non-Strategic|Consumer Type |PSC Consumer IBC|Industry Classification|Agency|Last Payment Date|Last Payment Amount|Meter Number|Meter Make|Device Category           |Last SIR Number|Last SIR CreatedOn|BillingMonth|BillType|BCM   |NormalUnits|NormalAmount|AverageUnits|AverageAmount|AdjustedUnits|AdjustedAmount|AssessedUnits|AssessedAmount|RegularUnits|RegularAmount|IRBDetectionUnits|IRBDetectionAmount|IRBRevisedUnits|IRBRevisedAmount|CurrentUnits|CurrentAmount|12MonthsAvgUnits|12MonthsAvgAmount|UnitBilledYTD|12MonthsUnits|12MonthsAmount|FICAMonth|OpeningBalance|MigrationBalance|AmountBilled|LPSBilled|LPSWaived|BankCharges|Payment|Adjustment|IBCTransfer|WriteOff|PreviousYearAllowance|DownPaymentRequest|DownPayment|ClearingAmount      |ClosingBalance|OutstandingDownPayment|SecurityDeposit|MNCVAdjustment|MNCVPayment|MNCVClearingAmount|A <=(366)|B (365)-(1)|C 0-30 |D 31-60|E 61-90|F 91-120|G 121-150|H 151-180|I 181-210|J 211-240|K 241-270|L 271-300|M 301-330|N 331-360|O 361-390|P 391-420|Q 421-450|R 451-480|S 481-510|T 511-540|U 541-570|V 571-600|W 601-630|X 631-660|Y 1021-1050|Y 1051-1080|Y 1081-1110|Y 1111-1140|Y 1141-1170|Y 1171-1200|Y 1201-1230|Y 1231-1260|Y 1261-1460|Y 1461-1825|Y 661-690|Y 691-720|Y 721-750|Y 751-780|Y 781-810|Y 811-840|Y 841-870|Y 871-900|Y 901-930|Y 931-960|Y 961-990|Y 991-1020|Z >=1826|GrossBilledYTD|NetCreditYTD|12MonthsGrossBilled|12MonthsNetCredit|12MonthsAvgGrossBilled|12MonthsAvgNetCredit|\n",
      "+--------------------+--------+----------------+---------------------+-------------------+---------------+----------------+--------+------------+-------------+-------------+-------------+------+---+-------+----+-----+------+----------------+----------------+----------------------+---------------+-----------+---+------+---------+-------+---------------+--------------+------+------------+--------------+------------+------------------------------+------+----------------+--------------+-------------------+-------------------+------------+------------------+------------+--------------+------------------+---------------+-------------------+-----------------------+--------------+----------------+-----------------------+------+-----------------+-------------------+------------+----------+--------------------------+---------------+------------------+------------+--------+------+-----------+------------+------------+-------------+-------------+--------------+-------------+--------------+------------+-------------+-----------------+------------------+---------------+----------------+------------+-------------+----------------+-----------------+-------------+-------------+--------------+---------+--------------+----------------+------------+---------+---------+-----------+-------+----------+-----------+--------+---------------------+------------------+-----------+--------------------+--------------+----------------------+---------------+--------------+-----------+------------------+---------+-----------+-------+-------+-------+--------+---------+---------+---------+---------+---------+---------+---------+---------+---------+---------+---------+---------+---------+---------+---------+---------+---------+---------+-----------+-----------+-----------+-----------+-----------+-----------+-----------+-----------+-----------+-----------+---------+---------+---------+---------+---------+---------+---------+---------+---------+---------+---------+----------+--------+--------------+------------+-------------------+-----------------+----------------------+--------------------+\n",
      "|40001336142631076894|NULL    |0101059880      |0615041580067        |40981              |LB228987       |400013361426    |31076894|41283       |2958465      |A2-C         |A2-C         |R1    |140|Liyar-I|140 |140  |ORD   |NULL            |2/2/2013        |2/2/2013              |1              |150        |ORD|SINGLE|06       |0615041|4.0            |4.0           |ACT   |28-May-2022 |3             |SHOP        |MR GHULAM HABIB KHAN   K.S-530|508747|NULL            |NULL          |NULL               |NULL               |NULL        |NULL              |NULL        |NULL          |NULL              |NULL           |C7                 |NULL                   |DOL Connection|NULL            |NULL                   |NULL  |24-Jan-2023      |4247.0             |SZ90859     |NULL      |METER; STATIC SINGLE PHASE|900001106475   |44775             |202301      |Regular |Normal|167.0      |4246.8      |0.0         |0.0          |0.0          |0.0           |0.0          |0.0           |167.0       |4246.8       |0.0              |0.0               |0.0            |1089.06         |167.0       |5335.86      |185.0           |6889.7636        |3386.0       |5180.0       |192913.38     |202301   |-0.48         |0.0             |5335.86     |0.0      |0.0      |0          |-4247.0|0.0       |0.0        |0       |0.0                  |0                 |0.0        |-4.5474735088646E-13|1088.38       |0                     |-7240.0        |0.0           |0.0        |0.0               |0.0      |0.0        |1088.38|0.0    |0.0    |0.0     |0.0      |0.0      |0.0      |0.0      |0.0      |0.0      |0.0      |0.0      |0.0      |0.0      |0.0      |0.0      |0.0      |0.0      |0.0      |0.0      |0.0      |0.0      |0.0        |0.0        |0.0        |0.0        |0.0        |0.0        |0.0        |0.0        |0.0        |0.0        |0.0      |0.0      |0.0      |0.0      |0.0      |0.0      |0.0      |0.0      |0.0      |0.0      |0.0      |0.0       |0.0     |70938.7       |-69850.0    |97679.59           |-96591.0         |6511.9726666667       |-6439.4             |\n",
      "+--------------------+--------+----------------+---------------------+-------------------+---------------+----------------+--------+------------+-------------+-------------+-------------+------+---+-------+----+-----+------+----------------+----------------+----------------------+---------------+-----------+---+------+---------+-------+---------------+--------------+------+------------+--------------+------------+------------------------------+------+----------------+--------------+-------------------+-------------------+------------+------------------+------------+--------------+------------------+---------------+-------------------+-----------------------+--------------+----------------+-----------------------+------+-----------------+-------------------+------------+----------+--------------------------+---------------+------------------+------------+--------+------+-----------+------------+------------+-------------+-------------+--------------+-------------+--------------+------------+-------------+-----------------+------------------+---------------+----------------+------------+-------------+----------------+-----------------+-------------+-------------+--------------+---------+--------------+----------------+------------+---------+---------+-----------+-------+----------+-----------+--------+---------------------+------------------+-----------+--------------------+--------------+----------------------+---------------+--------------+-----------+------------------+---------+-----------+-------+-------+-------+--------+---------+---------+---------+---------+---------+---------+---------+---------+---------+---------+---------+---------+---------+---------+---------+---------+---------+---------+-----------+-----------+-----------+-----------+-----------+-----------+-----------+-----------+-----------+-----------+---------+---------+---------+---------+---------+---------+---------+---------+---------+---------+---------+----------+--------+--------------+------------+-------------------+-----------------+----------------------+--------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# df.select('Time').limit(1).show()\n",
    "df.limit(1).show(truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "8c655072-84dd-40d9-b687-b6321da5eb02",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "++\n",
      "||\n",
      "++\n",
      "++\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"CREATE NAMESPACE nessie.oms\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "b792616d-40c3-43b7-92ee-e3a650812595",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "++\n",
      "||\n",
      "++\n",
      "++\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# spark.sql(\"DROP NAMESPACE nessie.test\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "9d118026-0ee4-4970-8a14-918749802bde",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "25/02/27 17:51:26 WARN CSVHeaderChecker: CSV header does not conform to the schema.\n",
      " Header: Createdon, punchCloseAt, OutageType, saifi, saidi, consumer_count_fdr, outageSubType, initialoffreason, htclosingreason, fdr_Id, fdr_name, grid_name, Relay, isemergency, israintripping, TAT, duration, dts_Id, consumer_count_fdr, datetime, tempmax, tempmin, temp, dew, humidity, precip, precipprob, precipcover, preciptype, snow, snowdepth, windgust, windspeed, winddir, sealevelpressure, cloudcover, visibility, solarradiation, solarenergy, uvindex, severerisk\n",
      " Schema: Createdon, punchCloseAt, OutageType, saifi, saidi, consumer_count_fdr5, outageSubType, initialoffreason, htclosingreason, fdr_Id, fdr_name, grid_name, Relay, isemergency, israintripping, TAT, duration, dts_Id, consumer_count_fdr18, datetime, tempmax, tempmin, temp, dew, humidity, precip, precipprob, precipcover, preciptype, snow, snowdepth, windgust, windspeed, winddir, sealevelpressure, cloudcover, visibility, solarradiation, solarenergy, uvindex, severerisk\n",
      "Expected: consumer_count_fdr5 but found: consumer_count_fdr\n",
      "CSV file: file:///mnt/HabibData/filtered_fault_data.csv\n",
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "# spark = SparkSession.builder.config(conf=conf).getOrCreate()\n",
    "# print(\"Spark Session Started\")\n",
    "df.writeTo(\"nessie.oms.oms_data_raw\").createOrReplace()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "564ad0e7-4cba-4eee-9918-bef63c4ef881",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
      "|Createdon,punchCloseAt,OutageType,saifi,saidi,consumer_count_fdr,outageSubType,initialoffreason,htclosingreason,fdr_Id,fdr_name,grid_name,Relay,isemergency,israintripping,TAT,duration,dts_Id,consumer_count_fdr,datetime,tempmax,tempmin,temp,dew,humidity,precip,precipprob,precipcover,preciptype,snow,snowdepth,windgust,windspeed,winddir,sealevelpressure,cloudcover,visibility,solarradiation,solarenergy,uvindex,severerisk|\n",
      "+------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
      "|                                                                                                                                                                                                                                                                                                                                                                                                                2023-01-01,2023-0...|\n",
      "|                                                                                                                                                                                                                                                                                                                                                                                                                2023-01-01,2023-0...|\n",
      "|                                                                                                                                                                                                                                                                                                                                                                                                                2023-01-01,2023-0...|\n",
      "|                                                                                                                                                                                                                                                                                                                                                                                                                2023-01-01,2023-0...|\n",
      "|                                                                                                                                                                                                                                                                                                                                                                                                                2023-01-01,2023-0...|\n",
      "|                                                                                                                                                                                                                                                                                                                                                                                                                2023-01-01,2023-0...|\n",
      "|                                                                                                                                                                                                                                                                                                                                                                                                                2023-01-01,2023-0...|\n",
      "|                                                                                                                                                                                                                                                                                                                                                                                                                2023-01-01,2023-0...|\n",
      "|                                                                                                                                                                                                                                                                                                                                                                                                                2023-01-01,2023-0...|\n",
      "|                                                                                                                                                                                                                                                                                                                                                                                                                2023-01-01,2023-0...|\n",
      "|                                                                                                                                                                                                                                                                                                                                                                                                                2023-01-01,2023-0...|\n",
      "|                                                                                                                                                                                                                                                                                                                                                                                                                2023-01-01,2023-0...|\n",
      "|                                                                                                                                                                                                                                                                                                                                                                                                                2023-01-01,2023-0...|\n",
      "|                                                                                                                                                                                                                                                                                                                                                                                                                2023-01-01,2023-0...|\n",
      "|                                                                                                                                                                                                                                                                                                                                                                                                                2023-01-01,2023-0...|\n",
      "|                                                                                                                                                                                                                                                                                                                                                                                                                2023-01-01,2023-0...|\n",
      "|                                                                                                                                                                                                                                                                                                                                                                                                                2023-01-01,2023-0...|\n",
      "|                                                                                                                                                                                                                                                                                                                                                                                                                2023-01-01,2023-0...|\n",
      "|                                                                                                                                                                                                                                                                                                                                                                                                                2023-01-01,2023-0...|\n",
      "|                                                                                                                                                                                                                                                                                                                                                                                                                2023-01-01,2023-0...|\n",
      "+------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.read.table(\"nessie.test.test_data_raw\").show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "fa87fdb8-9770-45dc-b3d4-7b12425c0705",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-------------------+-------------------+----------+------------+----------+---------------+------------------+--------------------+------------+--------------------+-----------------+--------------+----------------+\n",
      "|Fact_ID|Billing_Document_ID|Contract_Account_ID|  Due_Date|Total_Amount|Tax_Amount|Recovery_Amount|Outstanding_Amount|Average_Payment_Time|Units_Billed|Benefits_Adjustments|Import_Tax_Amount|Energy_Charges|Surcharge_Amount|\n",
      "+-------+-------------------+-------------------+----------+------------+----------+---------------+------------------+--------------------+------------+--------------------+-----------------+--------------+----------------+\n",
      "|      0|       100056932870|       400000000009|22.01.2024|   163068.55|      NULL|   2.72257278E8|   -2.7209420945E8|                NULL|      2538.0|             4697.81|              0.0|      91680.96|          2538.0|\n",
      "|      1|       100056953384|       400000000009|23.01.2024|   161306.28|      NULL|   2.72257278E8|   -2.7209597172E8|                NULL|      2506.0|             4846.12|              0.0|      90698.05|          2506.0|\n",
      "|      2|       100056934751|       400000000009|22.01.2024|   171915.17|      NULL|   2.72257278E8|   -2.7208536283E8|                NULL|      2624.0|             5839.47|              0.0|      94813.19|          2624.0|\n",
      "|      3|       100056959892|       400000000009|23.01.2024|   150890.86|      NULL|   2.72257278E8|   -2.7210638714E8|                NULL|      2332.0|             4632.08|              0.0|      85347.88|          2332.0|\n",
      "|      4|       100056935754|       400000000009|22.01.2024|   144523.23|      NULL|   2.72257278E8|   -2.7211275477E8|                NULL|      2250.0|             4149.45|              0.0|      82118.37|          2250.0|\n",
      "|      5|       100056986982|       400000000009|23.01.2024|   182576.34|      NULL|   2.72257278E8|   -2.7207470166E8|                NULL|      2778.0|              6183.6|              0.0|     101449.74|          2778.0|\n",
      "|      6|       100056935786|       400000000009|22.01.2024|   271835.11|      NULL|   2.72257278E8|   -2.7198544289E8|                NULL|      4161.0|             8100.92|              0.0|     150648.93|          4161.0|\n",
      "|      7|       100057103115|       400000000009|23.01.2024|    280078.9|      NULL|   2.72257278E8|    -2.719771991E8|                NULL|      4325.0|   7852.249999999999|              0.0|     157352.72|          4325.0|\n",
      "|      8|       100056937458|       400000000009|22.01.2024|   154683.79|      NULL|   2.72257278E8|   -2.7210259421E8|                NULL|      2397.0|             4551.93|              0.0|      87456.54|          2397.0|\n",
      "|      9|       100057112164|       400000000009|23.01.2024|   147032.72|      NULL|   2.72257278E8|   -2.7211024528E8|                NULL|      2206.0|             4223.54|              0.0|      80239.27|          2206.0|\n",
      "+-------+-------------------+-------------------+----------+------------+----------+---------------+------------------+--------------------+------------+--------------------+-----------------+--------------+----------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"SELECT * from nessie.fact_billing_and_recovery_final1.fact_billing_and_recovery_data_raw LIMIT 10;\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "28fa859c-b0b9-47c1-9bdc-85838ce2dd10",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "SLF4J: Failed to load class \"org.slf4j.impl.StaticLoggerBinder\".\n",
      "SLF4J: Defaulting to no-operation (NOP) logger implementation\n",
      "SLF4J: See http://www.slf4j.org/codes.html#StaticLoggerBinder for further details.\n"
     ]
    }
   ],
   "source": [
    "# Load data into DataFrames\n",
    "billing_data = spark.read.table(\"nessie.billing.billing_data_raw\")\n",
    "fault_tickets = spark.read.table(\"nessie.fault_tickets.fault_tickets_data_raw\")\n",
    "energy_consumption = spark.read.table(\"nessie.EnergyConsumptionFeederwise.EnergyConsumptionFeederwise_data_raw\")\n",
    "feeder_master = spark.read.table(\"nessie.feedermaster.feedermaster_data_raw\")\n",
    "feeder_voltage = spark.read.table(\"nessie.feedervoltage.feedervoltage_data_raw\")\n",
    "pmt_master = spark.read.table(\"nessie.pmtmaster.pmtmaster_data_raw\")\n",
    "power_report = spark.read.table(\"nessie.power_report.power_report_data_raw\")\n",
    "recovery_data = spark.read.table(\"nessie.recovery.recovery_data_raw\")\n",
    "\n",
    "# Register temporary views\n",
    "energy_consumption.createOrReplaceTempView(\"energy_consumption\")\n",
    "billing_data.createOrReplaceTempView(\"billing_data\")\n",
    "fault_tickets.createOrReplaceTempView(\"fault_tickets\")\n",
    "feeder_master.createOrReplaceTempView(\"feeder_master\")\n",
    "feeder_voltage.createOrReplaceTempView(\"feeder_voltage\")\n",
    "pmt_master.createOrReplaceTempView(\"pmt_master\")\n",
    "power_report.createOrReplaceTempView(\"power_report\")\n",
    "recovery_data.createOrReplaceTempView(\"recovery_data\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c71d9003-60ab-4527-a8bd-fb8b1f534e73",
   "metadata": {},
   "source": [
    "## Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "26df817c-931c-4d8f-84cb-ad0e8d1d0515",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 7:>                                                          (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------+----------+-------------------+\n",
      "|Overall Total|LPS Billed|Recovery_Percentage|\n",
      "+-------------+----------+-------------------+\n",
      "|     200000.0|    788.46|        2.0078846E7|\n",
      "|     200000.0|    443.67|        2.0044367E7|\n",
      "|     200000.0|   -260.87|        1.9973913E7|\n",
      "|     200000.0|   -426.19|        1.9957381E7|\n",
      "|     200000.0|   -124.58|        1.9987542E7|\n",
      "|     200000.0|       0.0|              2.0E7|\n",
      "|     200000.0|       0.0|              2.0E7|\n",
      "|     200000.0|    763.56|        2.0076356E7|\n",
      "|     200000.0|     259.2|         2.002592E7|\n",
      "|     200000.0|     260.0|           2.0026E7|\n",
      "+-------------+----------+-------------------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "df_heavy_join = spark.sql(\"\"\"\n",
    "SELECT \n",
    "    r.`Overall Total`,\n",
    "    b.`LPS Billed`, \n",
    "    (r.`Overall Total` + b.`LPS Billed`) * 100 AS Recovery_Percentage\n",
    "FROM recovery_data r\n",
    "INNER JOIN billing_data b \n",
    "ON r.`Posting date in the document` = b.`Posting date in the document`;\n",
    "\n",
    "\"\"\")\n",
    "df_heavy_join.show(10)  # Action: Triggers execution\n",
    "# from pyspark.sql.functions import col\n",
    "\n",
    "# numPartitions = 500\n",
    "# recovery_data = recovery_data.repartition(numPartitions)\n",
    "# billing_data = billing_data.repartition(numPartitions)\n",
    "\n",
    "\n",
    "# # Repartition both tables on \"IBC\" for better join performance\n",
    "# recovery_data = recovery_data.repartition(\"IBC\")\n",
    "# billing_data = billing_data.repartition(\"IBC\")\n",
    "\n",
    "# # Select only required columns to reduce memory usage\n",
    "# recovery_data = recovery_data.select(\"IBC\", \"Posting date in the document\", \"Overall Total\")\n",
    "# billing_data = billing_data.select(\"IBC\", \"Posting date in the document\", \"LPS Billed\")\n",
    "\n",
    "# # Perform the FULL OUTER JOIN\n",
    "# result = recovery_data.alias(\"r\").join(\n",
    "#     billing_data.alias(\"b\"),\n",
    "#     on=[\"IBC\", \"Posting date in the document\"],\n",
    "#     how=\"full_outer\"\n",
    "# ).select(\n",
    "#     col(\"Overall Total\"),\n",
    "#     col(\"LPS Billed\"),\n",
    "#     (col(\"Overall Total\") + col(\"LPS Billed\") * 100).alias(\"Recovery_Percentage\")\n",
    "# )\n",
    "\n",
    "# # Cache the result for repeated use\n",
    "# result.cache()\n",
    "\n",
    "# # Show the first 10 rows\n",
    "# result.show(10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96d8b44f-8229-4de0-9074-5101550442f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.sql(\"SHOW TABLES IN nessie\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "aae631aa-5ad8-4eae-8b54-6ff1a9a0d5cc",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------------------+---------+-------+\n",
      "|col_name             |data_type|comment|\n",
      "+---------------------+---------+-------+\n",
      "|Time                 |timestamp|NULL   |\n",
      "|Feeder               |int      |NULL   |\n",
      "|Device ID            |string   |NULL   |\n",
      "|DTS ID               |string   |NULL   |\n",
      "|Active Power (kW)    |string   |NULL   |\n",
      "|Reactive Power (kVAR)|string   |NULL   |\n",
      "|Apparent Power (kVA) |string   |NULL   |\n",
      "+---------------------+---------+-------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"DESCRIBE power_report\").show(truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5b75ff40-c132-49f1-83a4-e1509b523863",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------+---------+-------+\n",
      "|col_name         |data_type|comment|\n",
      "+-----------------+---------+-------+\n",
      "|Ticket No        |bigint   |NULL   |\n",
      "|Ticket Created at|string   |NULL   |\n",
      "|TicketDTSID      |string   |NULL   |\n",
      "|Feeder ID        |string   |NULL   |\n",
      "|Noti. No         |string   |NULL   |\n",
      "|UserStatus       |string   |NULL   |\n",
      "|SystemStatus     |string   |NULL   |\n",
      "|Notification Time|string   |NULL   |\n",
      "|Emergency Type   |string   |NULL   |\n",
      "|CompletedAt      |string   |NULL   |\n",
      "|Subject          |string   |NULL   |\n",
      "|AreaSecuredTime  |string   |NULL   |\n",
      "|TrueCallerTime   |string   |NULL   |\n",
      "|Item Description |string   |NULL   |\n",
      "|IsAreaSecured    |string   |NULL   |\n",
      "|AreaSecureTAT    |string   |NULL   |\n",
      "|IsTrueCaller     |string   |NULL   |\n",
      "|TrueCallerTAT    |string   |NULL   |\n",
      "|CreatedBy        |string   |NULL   |\n",
      "+-----------------+---------+-------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"DESCRIBE fault_tickets\").show(truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a493f22a-e6d4-4fd7-97a9-434fa340a17e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query = \"\"\"\n",
    "CREATE OR REPLACE TEMP VIEW fact_network_and_losses AS\n",
    "SELECT\n",
    "    -- Keys\n",
    "    fm.Feeder AS Feeder_ID,  -- Using `Feeder` from feeder_master\n",
    "    ec.`Device ID` AS Device_ID,  -- Corrected to use `Device ID` with backticks\n",
    "    pm.`DTS ID` AS Grid_Station_ID,  -- Corrected to use `DTS ID` with backticks\n",
    "    ft.`Ticket No` AS Ticket_No,\n",
    "    \n",
    "    -- Metrics\n",
    "    COUNT(ft.Subject) AS Fault_Count,\n",
    "    SUM(CASE WHEN ft.SystemStatus = 'UnPlanned' THEN 1 ELSE 0 END) +\n",
    "    SUM(ppr.`Active Power (kW)`) AS Energy_Created,  -- Changed to `ppr` as column exists there\n",
    "    SUM(ppr.`Reactive Power (kVAR)`) AS Energy_Transmitted,  -- Changed to `ppr` as column exists there\n",
    "    COUNT(ft.`Emergency Type`) AS Emergency_Count,\n",
    "    COUNT(ft.`Ticket No`) AS Tickets_Processed,\n",
    "    AVG(`ft`.`CompletedAt` - ft.`Notification Time`) AS Fault_Resolution_Time,\n",
    "    MAX(ft.Subject) AS Most_Common_Fault\n",
    "FROM\n",
    "    fault_tickets ft\n",
    "    INNER JOIN feeder_master fm ON ft.`Feeder ID` = fm.Feeder\n",
    "    INNER JOIN energy_consumption ec ON fm.Feeder = ec.FeederID\n",
    "    INNER JOIN pmt_master pm ON pm.`DTS ID` = ft.`TicketDTSID`\n",
    "    INNER JOIN power_report ppr ON ppr.`Device ID` = ec.`Device ID`\n",
    "GROUP BY\n",
    "    fm.Feeder, ec.`Device ID`, pm.`DTS ID`, ft.`Ticket No`;\n",
    "\"\"\"\n",
    "\n",
    "# Execute the query\n",
    "spark.sql(query)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "348bc469-db5d-4075-9c09-4acf14ced16a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 0:>                                                          (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------------+-------------+------------+----------------------+------------------+--------------+------------+--------------+--------------+-------------------------------------------+----------------------------+------------------+--------------------------------------+----------------+------------+-------------------+-----------------------------------+---------------+---------------------------------------+----------+-------------+-----------------------+----------------+------+---------+----------------------------+-----------------+------+-------------------+---------+--------------------+---------------+-------------------------------------+-------------------+--------------+------------------+---------------+----------------+-------------------+---------------------+--------------------+------------+--------------------+--------------------+----------------+--------------+-------------------+-------------------+-------------+----------------+-----------------+------------+----------+--------------------+----------------------+------------------------+---------------+--------------+--------------+--------------------+----------------+--------------+-------------+--------------------+-------------------+-----------------+--------+-------+---------+----------+--------------------+----------+--------------------+---------+--------------------+---------+--------------------+-------+----------+--------------+-------------+---------------+--------------------------+-------------------------+--------------------+--------------------+--------------------+---------+-------------------+--------------+--------------------+--------------------+----------+-------------------+---------------------------+-----------------------+---------------------------+-----------------------+-------------------------------+---------------------------+------------------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+---------------------------+--------------+-----------+-------------+\n",
      "|Business Partner|Industry Code|   PSC's IBC|Strategic/NonStrategic|PSC Classification|PSC Department|PSC Ministry|PSC Sub - Dept|PSC - Sub Area|Contract Account (Partner-Independent Data)|Posting date in the document|Reversal Indicator|Account Determination ID for Contracts|Billing Document|Meter Reader|Meter Reader PR NO.|Contract Number: Utilities Industry|Consumer Status|Installation Number: Utilities Industry|       IBC|Billing Class|Supply Guarantee Reason|   Rate Category|Region|Cycle Day|Industry Type Classification|Ord-Ind-PSC (OIP)|Tariff|BCM/Reversal Reason|Bill Type|Due Date (Print Doc)|Own Consumption|Issue Date (Print Doc's Posting Date)|Legacy Consumer No.|Print Document|Revenue Adjustment|    Unit Ranges|Unit Ranges Ind.|Calendar Year/Month|Calendar year/quarter|Periodic Quarterly A|GST_RETAILER|Import-OffPeak Units|Import-On Peak Units|GST (Further 1%)|GST (Extra 5%)|GST (Steel Melters)|Import Amt NetMtrng|RET_EMP_BENEF|No. Billing Docs|No. of Print Docs|Units Billed|Net Amount|Award Winner Benefit|GST on Retailers (5 %)|GST on Retailers (7.5 %)|Sanctioned Load|Connected Load|Maximum Demand|Additional Surcharge|Electricity Duty|Energy Charges|Fixed Charges|Emp Benefit -Officer|Free Benefit Amount|Fuel Adj. Charges|ISP Adj.|    GST|ID Meters|Income Tax|Income Tax Surcharge|Meter Rent|Misc. Energy Charges|PM Relief|Power Factor Penalty|Retro FSA|Sales Tax Adjustment|TVL Fee|LPS Billed|Off Peak Units|On Peak Units|Seasonal Impact|Uniform Qtr.Adj. on Import|Retro FCA Chrgs on Import|Deferred FCA Adj. Im|Deferred FCA Adjustm|Power holding Ltd. S|Surcharge|ISPA Adj. Ind. Peak|Quarterly Adj.|PM Relief Res. Comm.|Uniform Quatrly Adj.|MUCT (KMC)|Kissan Package 2022|New Qtr Adj Import Off Peak|New Qtr Adj Import Peak|New Qtr Adj Export Off Peak|New Qtr Adj Export Peak|Import Units Off Peak  Current|Import Units Peak  Current|Import Units Non-TOU  Current|Uniform Quarterly Ad|Quarterly Adj. Curre|Consp-Non IND-Import|Consp-Non TOD-Import|Normal GST on Import|WithHolding GST -IMP|Withholding ITax-IMP|No. of Print Docs/Bill Docs|Zero Rate ISPA|Surcharge_1|GST on Marble|\n",
      "+----------------+-------------+------------+----------------------+------------------+--------------+------------+--------------+--------------+-------------------------------------------+----------------------------+------------------+--------------------------------------+----------------+------------+-------------------+-----------------------------------+---------------+---------------------------------------+----------+-------------+-----------------------+----------------+------+---------+----------------------------+-----------------+------+-------------------+---------+--------------------+---------------+-------------------------------------+-------------------+--------------+------------------+---------------+----------------+-------------------+---------------------+--------------------+------------+--------------------+--------------------+----------------+--------------+-------------------+-------------------+-------------+----------------+-----------------+------------+----------+--------------------+----------------------+------------------------+---------------+--------------+--------------+--------------------+----------------+--------------+-------------+--------------------+-------------------+-----------------+--------+-------+---------+----------+--------------------+----------+--------------------+---------+--------------------+---------+--------------------+-------+----------+--------------+-------------+---------------+--------------------------+-------------------------+--------------------+--------------------+--------------------+---------+-------------------+--------------+--------------------+--------------------+----------+-------------------+---------------------------+-----------------------+---------------------------+-----------------------+-------------------------------+---------------------------+------------------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+---------------------------+--------------+-----------+-------------+\n",
      "|     SHAHZAD ALI| Not assigned|Not assigned|                  NULL|      Not assigned|  Not assigned|Not assigned|  Not assigned|  Not assigned|                               400038636810|                  08.01.2024|              NULL|                           Residential|    110064529724|        NULL|                  0|                           33652916|         ACTIVE|                             7003696797|   DEFENCE|     Domestic|           Not assigned|A1-R Residential|    C1|        2|                Not assigned|              ORD|   A1-|                  N|  Regular|          22.01.2024|   Not assigned|                           08.01.2024|           LC443343|  718014384241|              NULL|101 - 200 Units|1 - 10,000 Units|              12024|                20241|                 0.0|         0.0|                 0.0|                 0.0|             0.0|           0.0|                0.0|                0.0|          0.0|               1|              1.0|       173.0|   7080.21|                 0.0|                   0.0|                     0.0|            4.0|           4.0|           0.0|                 0.0|           88.23|       3970.35|          0.0|                 0.0|                0.0|              0.0|     0.0|1074.69|      0.0|       0.0|                 0.0|       0.0|                 0.0|      0.0|                 0.0|      0.0|                 0.0|   35.0|    588.23|         173.0|          0.0|            0.0|                       0.0|                      0.0|                 0.0|                 0.0|              558.79|   262.96|                0.0|           0.0|                 0.0|              399.97|       0.0|                0.0|                        0.0|                    0.0|                      109.7|                    0.0|                            0.0|                        0.0|                           0.0|              567.68|               12.84|                 0.0|                 0.0|                 0.0|                 0.0|                 0.0|                          1|           0.0|        0.0|          0.0|\n",
      "|            Raja| Not assigned|Not assigned|                  NULL|      Not assigned|  Not assigned|Not assigned|  Not assigned|  Not assigned|                               400038636829|                  08.01.2024|              NULL|                           Residential|    260028818682|        NULL|                  0|                           33672100|         ACTIVE|                             7003708319|  LAYARI-I|     Domestic|           Not assigned|A1-R Residential|    C7|        2|                Not assigned|              ORD|   A1-|                  N|  Regular|          22.01.2024|   Not assigned|                           08.01.2024|           LC444913|  721014317532|              NULL|101 - 200 Units|1 - 10,000 Units|              12024|                20241|                 0.0|         0.0|                 0.0|                 0.0|             0.0|           0.0|                0.0|                0.0|          0.0|               1|              1.0|       117.0|   4905.73|                 0.0|                   0.0|                     0.0|            2.0|           2.0|           0.0|                 0.0|            61.0|       2685.15|          0.0|                 0.0|                0.0|              0.0|     0.0| 742.99|      0.0|       0.0|                 0.0|       0.0|                 0.0|      0.0|                 0.0|      0.0|                 0.0|   35.0|    406.67|         117.0|          0.0|            0.0|                       0.0|                      0.0|                 0.0|                 0.0|              377.91|   177.84|                0.0|           0.0|                 0.0|              336.96|       0.0|                0.0|                        0.0|                    0.0|                      96.28|                    0.0|                            0.0|                        0.0|                           0.0|              383.92|                8.68|                 0.0|                 0.0|                 0.0|                 0.0|                 0.0|                          1|           0.0|        0.0|          0.0|\n",
      "|       SAMIULLAH| Not assigned|Not assigned|                  NULL|      Not assigned|  Not assigned|Not assigned|  Not assigned|  Not assigned|                               400038636845|                  08.01.2024|              NULL|                            Commercial|    663000759170|        NULL|                  0|                           33655547|         ACTIVE|                             7003702512|TIPUSULTAN|   Commercial|           Not assigned| A2-C Commercial|    C2|        2|                Not assigned|              ORD|   A2-|                  N|  Regular|          22.01.2024|   Not assigned|                           08.01.2024|           AM263283|  724014068685|              NULL|301 - 700 Units|1 - 10,000 Units|              12024|                20241|                 0.0|         0.0|                 0.0|                 0.0|          979.03|       2937.09|                0.0|                0.0|          0.0|               1|              1.0|       485.0|  36343.17|                 0.0|                   0.0|                     0.0|            4.0|           4.0|           0.0|                 0.0|          479.92|      18308.75|          0.0|                 0.0|                0.0|              0.0|     0.0|4405.63|      0.0|    3485.7|                 0.0|       0.0|                 0.0|      0.0|                 0.0|      0.0|                 0.0|   60.0|   2399.58|         485.0|          0.0|            0.0|                       0.0|                      0.0|                 0.0|                 0.0|             1566.55|    737.2|                0.0|           0.0|                 0.0|             1358.88|       0.0|                0.0|                        0.0|                    0.0|                     396.95|                    0.0|                            0.0|                        0.0|                           0.0|             1591.48|               35.99|                 0.0|                 0.0|                 0.0|                 0.0|                 0.0|                          1|           0.0|        0.0|          0.0|\n",
      "|      NOOR ISLAM| Not assigned|Not assigned|                  NULL|      Not assigned|  Not assigned|Not assigned|  Not assigned|  Not assigned|                               400038636896|                  08.01.2024|              NULL|                           Residential|    260028818654|        NULL|                  0|                           33683506|         ACTIVE|                             7003708068|  LAYARI-I|     Domestic|           Not assigned|A1-R Residential|    C7|        2|                Not assigned|              ORD|   A1-|                  A|  Regular|          22.01.2024|   Not assigned|                           08.01.2024|           LC444855|  721014317534|              NULL| 51 - 100 Units|1 - 10,000 Units|              12024|                20241|                 0.0|         0.0|                 0.0|                 0.0|             0.0|           0.0|                0.0|                0.0|          0.0|               1|              1.0|        66.0|   1312.17|                 0.0|                   0.0|                     0.0|            2.0|           2.0|           0.0|                 0.0|            16.0|        510.84|          0.0|                 0.0|                0.0|              0.0|     0.0| 194.82|      0.0|       0.0|                 0.0|       0.0|                 0.0|      0.0|                 0.0|      0.0|                 0.0|   35.0|    106.64|          66.0|          0.0|            0.0|                       0.0|                      0.0|                 0.0|                 0.0|               28.38|   100.32|                0.0|           0.0|                 0.0|               131.9|       0.0|                0.0|                        0.0|                    0.0|                      73.44|                    0.0|                            0.0|                        0.0|                           0.0|              216.57|                 4.9|                 0.0|                 0.0|                 0.0|                 0.0|                 0.0|                          1|           0.0|        0.0|          0.0|\n",
      "| Tareeqa Khatoon| Not assigned|Not assigned|                  NULL|      Not assigned|  Not assigned|Not assigned|  Not assigned|  Not assigned|                               400038636907|                  08.01.2024|              NULL|                           Residential|    260028818662|        NULL|                  0|                           33682835|         ACTIVE|                             7003708078|  LAYARI-I|     Domestic|           Not assigned|A1-R Residential|    C7|        2|                Not assigned|              ORD|   A1-|                  N|  Regular|          22.01.2024|   Not assigned|                           08.01.2024|           LC444873|  721014317535|              NULL|  21 - 50 Units|1 - 10,000 Units|              12024|                20241|                 0.0|         0.0|                 0.0|                 0.0|             0.0|           0.0|                0.0|                0.0|          0.0|               1|              1.0|        24.0|    787.99|                 0.0|                   0.0|                     0.0|            2.0|           2.0|           0.0|                 0.0|            9.43|        185.76|          0.0|                 0.0|                0.0|              0.0|     0.0| 114.86|      0.0|       0.0|                 0.0|       0.0|                 0.0|      0.0|                 0.0|      0.0|                 0.0|   35.0|     62.87|          24.0|          0.0|            0.0|                       0.0|                      0.0|                 0.0|                 0.0|               10.32|    36.48|                0.0|           0.0|                 0.0|              224.64|       0.0|                0.0|                        0.0|                    0.0|                      90.97|                    0.0|                            0.0|                        0.0|                           0.0|               78.75|                1.78|                 0.0|                 0.0|                 0.0|                 0.0|                 0.0|                          1|           0.0|        0.0|          0.0|\n",
      "| MUHAMMAD ISMAIL| Not assigned|Not assigned|                  NULL|      Not assigned|  Not assigned|Not assigned|  Not assigned|  Not assigned|                               400038639070|                  08.01.2024|              NULL|                           Residential|    260028818669|        NULL|                  0|                           33688513|         ACTIVE|                             7003708086|  LAYARI-I|     Domestic|           Not assigned|A1-R Residential|    C7|        2|                Not assigned|              ORD|   A1-|                  N|  Regular|          22.01.2024|   Not assigned|                           08.01.2024|           LC444880|  721014317537|              NULL| 51 - 100 Units|1 - 10,000 Units|              12024|                20241|                 0.0|         0.0|                 0.0|                 0.0|             0.0|           0.0|                0.0|                0.0|          0.0|               1|              1.0|        79.0|   1452.41|                 0.0|                   0.0|                     0.0|            2.0|           2.0|           0.0|                 0.0|           17.75|        611.46|          0.0|                 0.0|                0.0|              0.0|     0.0| 216.22|      0.0|       0.0|                 0.0|       0.0|                 0.0|      0.0|                 0.0|      0.0|                 0.0|   35.0|    118.35|          79.0|          0.0|            0.0|                       0.0|                      0.0|                 0.0|                 0.0|               33.97|   120.08|                0.0|           0.0|                 0.0|               90.52|       0.0|                0.0|                        0.0|                    0.0|                      62.32|                    0.0|                            0.0|                        0.0|                           0.0|              259.23|                5.86|                 0.0|                 0.0|                 0.0|                 0.0|                 0.0|                          1|           0.0|        0.0|          0.0|\n",
      "|        MUHAMMAD| Not assigned|Not assigned|                  NULL|      Not assigned|  Not assigned|Not assigned|  Not assigned|  Not assigned|                               400038639208|                  08.01.2024|              NULL|                            Commercial|    260028818685|        NULL|                  0|                           33689967|         ACTIVE|                             7003708332|  LAYARI-I|   Commercial|           Not assigned| A2-C Commercial|    C7|        2|                Not assigned|              ORD|   A2-|                  N|  Regular|          22.01.2024|   Not assigned|                           08.01.2024|           LC444916|  721014317538|              NULL|        Minimum|         Minimum|              12024|                20241|                 0.0|         0.0|                 0.0|                 0.0|            7.14|          8.93|                0.0|                0.0|          0.0|               1|              1.0|         0.0|    286.69|                 0.0|                   0.0|                     0.0|            2.0|           2.0|           0.0|                 0.0|             3.5|           0.0|          0.0|                 0.0|                0.0|              0.0|     0.0|  32.13|      0.0|       0.0|                 0.0|       0.0|               144.5|      0.0|                 0.0|      0.0|                 0.0|   60.0|      17.5|           0.0|          0.0|            0.0|                       0.0|                      0.0|                 0.0|                 0.0|                 0.0|      0.0|                0.0|           0.0|                 0.0|               19.94|       0.0|                0.0|                        0.0|                    0.0|                      10.55|                    0.0|                            0.0|                        0.0|                           0.0|                 0.0|                 0.0|                 0.0|                 0.0|                 0.0|                 0.0|                 0.0|                          1|           0.0|        0.0|          0.0|\n",
      "|       ALAM KHAN| Not assigned|Not assigned|                  NULL|      Not assigned|  Not assigned|Not assigned|  Not assigned|  Not assigned|                               400038639267|                  08.01.2024|              NULL|                           Residential|    110064529741|        NULL|                  0|                           33673224|         ACTIVE|                             7003716806|   DEFENCE|     Domestic|           Not assigned|A1-R Residential|    C1|        2|                Not assigned|              ORD|   A1-|                  N|  Regular|          22.01.2024|   Not assigned|                           08.01.2024|           LC445738|  718014384242|              NULL|        Minimum|         Minimum|              12024|                20241|                 0.0|         0.0|                 0.0|                 0.0|             0.0|           0.0|                0.0|                0.0|          0.0|               1|              1.0|         0.0|     123.5|                 0.0|                   0.0|                     0.0|            2.0|           2.0|           0.0|                 0.0|             0.0|           0.0|          0.0|                 0.0|                0.0|              0.0|     0.0|   13.5|      0.0|       0.0|                 0.0|       0.0|                75.0|      0.0|                 0.0|      0.0|                 0.0|   35.0|       7.5|           0.0|          0.0|            0.0|                       0.0|                      0.0|                 0.0|                 0.0|                 0.0|      0.0|                0.0|           0.0|                 0.0|                 0.0|       0.0|                0.0|                        0.0|                    0.0|                        0.0|                    0.0|                            0.0|                        0.0|                           0.0|                 0.0|                 0.0|                 0.0|                 0.0|                 0.0|                 0.0|                 0.0|                          1|           0.0|        0.0|          0.0|\n",
      "|       ALAM KHAN| Not assigned|Not assigned|                  NULL|      Not assigned|  Not assigned|Not assigned|  Not assigned|  Not assigned|                               400038639275|                  08.01.2024|              NULL|                           Residential|    110064529742|        NULL|                  0|                           33673225|         ACTIVE|                             7003716807|   DEFENCE|     Domestic|           Not assigned|A1-R Residential|    C1|        2|                Not assigned|              ORD|   A1-|                  N|  Regular|          22.01.2024|   Not assigned|                           08.01.2024|           LC445739|  718014384243|              NULL|  21 - 50 Units|1 - 10,000 Units|              12024|                20241|                 0.0|         0.0|                 0.0|                 0.0|             0.0|           0.0|                0.0|                0.0|          0.0|               1|              1.0|        48.0|    961.21|                 0.0|                   0.0|                     0.0|            2.0|           2.0|           0.0|                 0.0|            11.6|        371.52|          0.0|                 0.0|                0.0|              0.0|     0.0| 141.29|      0.0|       0.0|                 0.0|       0.0|                 0.0|      0.0|                 0.0|      0.0|                 0.0|   35.0|     77.33|          48.0|          0.0|            0.0|                       0.0|                      0.0|                 0.0|                 0.0|               20.64|    72.96|                0.0|           0.0|                 0.0|              143.99|       0.0|                0.0|                        0.0|                    0.0|                       3.14|                    0.0|                            0.0|                        0.0|                           0.0|              157.51|                3.56|                 0.0|                 0.0|                 0.0|                 0.0|                 0.0|                          1|           0.0|        0.0|          0.0|\n",
      "|     ISRAR AHMED| Not assigned|Not assigned|                  NULL|      Not assigned|  Not assigned|Not assigned|  Not assigned|  Not assigned|                               400038613047|                  08.01.2024|              NULL|                           Residential|    642001343948|        NULL|                  0|                           33664008|         ACTIVE|                             7003701603|    GARDEN|     Domestic|           Not assigned|A1-R Residential|    C2|        2|                Not assigned|              ORD|   A1-|                  N|  Regular|          22.01.2024|   Not assigned|                           08.01.2024|           LC443755|  721014313880|              NULL|101 - 200 Units|1 - 10,000 Units|              12024|                20241|                 0.0|         0.0|                 0.0|                 0.0|             0.0|           0.0|                0.0|                0.0|          0.0|               1|              1.0|       161.0|    6749.3|                 0.0|                   0.0|                     0.0|            4.0|           4.0|           0.0|                 0.0|           84.09|       3694.95|          0.0|                 0.0|                0.0|              0.0|     0.0|1024.21|      0.0|       0.0|                 0.0|       0.0|                 0.0|      0.0|                 0.0|      0.0|                 0.0|   35.0|     560.6|         161.0|          0.0|            0.0|                       0.0|                      0.0|                 0.0|                 0.0|              520.03|   244.72|                0.0|           0.0|                 0.0|              423.22|       0.0|                0.0|                        0.0|                    0.0|                     182.82|                    0.0|                            0.0|                        0.0|                           0.0|              528.31|               11.95|                 0.0|                 0.0|                 0.0|                 0.0|                 0.0|                          1|           0.0|        0.0|          0.0|\n",
      "+----------------+-------------+------------+----------------------+------------------+--------------+------------+--------------+--------------+-------------------------------------------+----------------------------+------------------+--------------------------------------+----------------+------------+-------------------+-----------------------------------+---------------+---------------------------------------+----------+-------------+-----------------------+----------------+------+---------+----------------------------+-----------------+------+-------------------+---------+--------------------+---------------+-------------------------------------+-------------------+--------------+------------------+---------------+----------------+-------------------+---------------------+--------------------+------------+--------------------+--------------------+----------------+--------------+-------------------+-------------------+-------------+----------------+-----------------+------------+----------+--------------------+----------------------+------------------------+---------------+--------------+--------------+--------------------+----------------+--------------+-------------+--------------------+-------------------+-----------------+--------+-------+---------+----------+--------------------+----------+--------------------+---------+--------------------+---------+--------------------+-------+----------+--------------+-------------+---------------+--------------------------+-------------------------+--------------------+--------------------+--------------------+---------+-------------------+--------------+--------------------+--------------------+----------+-------------------+---------------------------+-----------------------+---------------------------+-----------------------+-------------------------------+---------------------------+------------------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+---------------------------+--------------+-----------+-------------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "spark.sql(\"SELECT * FROM billing_data\").show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "f2f62df5-e659-443e-888b-9710c9f55f67",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hakuna matata, table banata\n"
     ]
    }
   ],
   "source": [
    "query2 = \"\"\"\n",
    "CREATE OR REPLACE TEMP VIEW fact_billing_and_recovery AS\n",
    "SELECT\n",
    "    -- Primary Key\n",
    "    MONOTONICALLY_INCREASING_ID() AS Fact_ID, -- Unique identifier for each record in the fact table\n",
    "    \n",
    "    -- Foreign Keys\n",
    "    b.`Billing Document` AS Billing_Document_ID, -- Foreign key to billing_data\n",
    "    r.`Contract Account (Partner-Independent Data)` AS Contract_Account_ID, -- Foreign key to recovery_data\n",
    "    \n",
    "    -- Additional Date Fields for Analysis\n",
    "    b.`Due Date (Print Doc)` AS Due_Date, -- Correct column with date conversion\n",
    "    \n",
    "    -- Metrics\n",
    "    SUM(b.`Net Amount`) AS Total_Amount, -- Summation of Net Amount for Total_Amount\n",
    "    SUM(\n",
    "        b.Tariff +\n",
    "        b.GST +\n",
    "        b.`GST (Further 1%)` +\n",
    "        b.`GST (Extra 5%)` +\n",
    "        b.`GST_Retailer` +\n",
    "        b.`GST on Retailers (5 %)` +\n",
    "        b.`GST on Retailers (7.5 %)` +\n",
    "        b.`GST` +\n",
    "        b.`Income Tax` +\n",
    "        b.`Income Tax Surcharge` +\n",
    "        b.`Normal GST on import` +\n",
    "        b.`WithHolding GST -IMP` +\n",
    "        b.`WithHolding ITax-IMP` +\n",
    "        b.Surcharge +\n",
    "        b.`Surcharge_1` +\n",
    "        b.`GST on Marble` +\n",
    "        b.`Electricity Duty` +\n",
    "        b.`Additional Surcharge` +\n",
    "        b.`MUCT (KMC)`\n",
    "    ) AS Tax_Amount, -- Summation of all specified tax components\n",
    "    SUM(r.`Total Amount`) AS Recovery_Amount, -- Total recovery amount from recovery\n",
    "    (SUM(b.`Net Amount`) - SUM(r.`Total Amount`)) AS Outstanding_Amount, -- Difference between Total Amount and Recovery Amount\n",
    "    AVG(DATEDIFF(r.`Document Date`, b.`Issue Date (Print Doc's Posting Date)`)) AS Average_Payment_Time, -- Document Date - Issue Date for payment time\n",
    "    SUM(b.`Units Billed`) AS Units_Billed, -- Total units billed\n",
    "    SUM(\n",
    "        b.`Emp Benefit -Officer` +\n",
    "        b.`Free Benefit Amount` +\n",
    "        b.`PM Relief` +\n",
    "        b.`PM Relief Res. Comm.` +\n",
    "        b.`Award Winner Benefit` +\n",
    "        b.`ISP Adj.` +\n",
    "        b.`Fuel Adj. Charges` +\n",
    "        b.`Sales Tax Adjustment` +\n",
    "        b.`Uniform Qtr.Adj. on Import` +\n",
    "        b.`Deferred FCA Adj. Im` +\n",
    "        b.`Deferred FCA Adjustm` +\n",
    "        b.`ISPA Adj. Ind. Peak` +\n",
    "        b.`Quarterly Adj.` +\n",
    "        b.`Uniform Quatrly Adj.` +\n",
    "        b.`New Qtr Adj Import Off Peak` +\n",
    "        b.`New Qtr Adj Import Peak` +\n",
    "        b.`New Qtr Adj Export Off Peak` +\n",
    "        b.`New Qtr Adj Export Peak` +\n",
    "        b.`Quarterly Adj. Curre`\n",
    "    ) AS Benefits_Adjustments, -- Summation of benefits and adjustments\n",
    "    SUM(\n",
    "        b.`Import-OffPeak Units` +\n",
    "        b.`Import-On Peak Units` +\n",
    "        b.`Import Units Off Peak  Current` +\n",
    "        b.`Import Units Non-TOU  Current` +\n",
    "        b.`Consp-Non TOD-Import`\n",
    "    ) AS Import_Tax_Amount, -- Summation of import-related taxes\n",
    "    SUM(b.`Energy Charges`) AS Energy_Charges, -- Energy charges from billing\n",
    "    SUM(b.`Units Billed`) AS Surcharge_Amount -- Replacing with summation of units billed\n",
    "FROM\n",
    "    billing_data b\n",
    "    INNER JOIN recovery_data r \n",
    "    ON b.`Contract Account (Partner-Independent Data)` = r.`Contract Account (Partner-Independent Data)`\n",
    "WHERE\n",
    "    b.`Contract Account (Partner-Independent Data)` IS NOT NULL -- Exclude rows with NULL Contract Account\n",
    "GROUP BY\n",
    "    b.`Billing Document`,\n",
    "    r.`Contract Account (Partner-Independent Data)`,\n",
    "    b.`Due Date (Print Doc)`;\n",
    "\"\"\"\n",
    "\n",
    "spark.sql(query2)\n",
    "print(\"hakuna matata, table banata\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "72144508-c87f-4a91-88fa-a7be037ee119",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 23:>                                                         (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-------------------+-------------------+----------+------------+----------+---------------+------------------+--------------------+------------+--------------------+-----------------+--------------+----------------+\n",
      "|Fact_ID|Billing_Document_ID|Contract_Account_ID|  Due_Date|Total_Amount|Tax_Amount|Recovery_Amount|Outstanding_Amount|Average_Payment_Time|Units_Billed|Benefits_Adjustments|Import_Tax_Amount|Energy_Charges|Surcharge_Amount|\n",
      "+-------+-------------------+-------------------+----------+------------+----------+---------------+------------------+--------------------+------------+--------------------+-----------------+--------------+----------------+\n",
      "|      0|       100056932870|       400000000009|22.01.2024|   163068.55|      NULL|   2.72257278E8|   -2.7209420945E8|                NULL|      2538.0|             4697.81|              0.0|      91680.96|          2538.0|\n",
      "|      1|       100056934751|       400000000009|22.01.2024|   171915.17|      NULL|   2.72257278E8|   -2.7208536283E8|                NULL|      2624.0|             5839.47|              0.0|      94813.19|          2624.0|\n",
      "|      2|       100056935754|       400000000009|22.01.2024|   144523.23|      NULL|   2.72257278E8|   -2.7211275477E8|                NULL|      2250.0|             4149.45|              0.0|      82118.37|          2250.0|\n",
      "|      3|       100056935786|       400000000009|22.01.2024|   271835.11|      NULL|   2.72257278E8|   -2.7198544289E8|                NULL|      4161.0|             8100.92|              0.0|     150648.93|          4161.0|\n",
      "|      4|       100056937458|       400000000009|22.01.2024|   154683.79|      NULL|   2.72257278E8|   -2.7210259421E8|                NULL|      2397.0|             4551.93|              0.0|      87456.54|          2397.0|\n",
      "|      5|       100056944421|       400000000009|22.01.2024|   234953.92|      NULL|   2.72257278E8|   -2.7202232408E8|                NULL|      3652.0|   8792.380000000001|              0.0|      133279.3|          3652.0|\n",
      "|      6|       100056948040|       400000000009|22.01.2024|   186821.35|      NULL|   2.72257278E8|   -2.7207045665E8|                NULL|      2908.0|              5985.6|              0.0|     102885.04|          2908.0|\n",
      "|      7|       100056958040|       400000000009|22.01.2024|   137518.05|      NULL|   2.72257278E8|   -2.7211975995E8|                NULL|      2072.0|  3526.8299999999995|              0.0|      76375.94|          2072.0|\n",
      "|      8|       100056964324|       400000000009|22.01.2024|   218781.55|      NULL|   2.72257278E8|   -2.7203849645E8|                NULL|      3482.0|             6688.02|              0.0|     123193.16|          3482.0|\n",
      "|      9|       110064545915|       400000000009|22.01.2024|   160502.08|      NULL|   2.72257278E8|   -2.7209677592E8|                NULL|      2432.0|             4456.12|              0.0|       90056.0|          2432.0|\n",
      "+-------+-------------------+-------------------+----------+------------+----------+---------------+------------------+--------------------+------------+--------------------+-----------------+--------------+----------------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "spark.sql(\"SELECT * FROM fact_billing_and_recovery\").show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "18586b00-5e59-4927-aa4a-abaab55a2156",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "++\n",
      "||\n",
      "++\n",
      "++\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# spark.sql(\"CREATE NAMESPACE nessie.fact_network_and_loss;\").show()\n",
    "spark.sql(\"CREATE NAMESPACE nessie.fact_billing_and_recovery_final1;\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "fe701fc0-4890-4cc0-b791-9d6479603f3e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "++\n",
      "||\n",
      "++\n",
      "++\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"CREATE NAMESPACE nessie.fact_network_and_losses;\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89e43fca-f895-4fc5-8a40-20edb4cc44cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "fact_network_and_loss_df = spark.sql(\"SELECT * FROM fact_network_and_losses\")\n",
    "\n",
    "fact_network_and_loss_df.writeTo(\"nessie.fact_network_and_losses.fact_network_and_loss_data_raw\").createOrReplace()\n",
    "\n",
    "print (\"minio shinio here we go!!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "bfba9326-33ec-4d24-8451-30eaec167d50",
   "metadata": {},
   "outputs": [
    {
     "ename": "AnalysisException",
     "evalue": "[TABLE_OR_VIEW_NOT_FOUND] The table or view `fact_billing_and_recovery` cannot be found. Verify the spelling and correctness of the schema and catalog.\nIf you did not qualify the name with a schema, verify the current_schema() output, or qualify the name with the correct schema and catalog.\nTo tolerate the error on drop use DROP VIEW IF EXISTS or DROP TABLE IF EXISTS.; line 1 pos 14;\n'Project [*]\n+- 'UnresolvedRelation [fact_billing_and_recovery], [], false\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAnalysisException\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[126], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Assuming you have already created a DataFrame `fact_billing_and_recovery`\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m fact_billing_and_recovery_df \u001b[38;5;241m=\u001b[39m \u001b[43mspark\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msql\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mSELECT * FROM fact_billing_and_recovery\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;66;03m# Writing the DataFrame into Dremio\u001b[39;00m\n\u001b[1;32m      5\u001b[0m fact_billing_and_recovery_df\u001b[38;5;241m.\u001b[39mwriteTo(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnessie.fact_billing_and_recovery_final1.fact_billing_and_recovery_data_raw\u001b[39m\u001b[38;5;124m\"\u001b[39m)\u001b[38;5;241m.\u001b[39mcreateOrReplace()\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/pyspark/sql/session.py:1631\u001b[0m, in \u001b[0;36mSparkSession.sql\u001b[0;34m(self, sqlQuery, args, **kwargs)\u001b[0m\n\u001b[1;32m   1627\u001b[0m         \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jvm \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1628\u001b[0m         litArgs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jvm\u001b[38;5;241m.\u001b[39mPythonUtils\u001b[38;5;241m.\u001b[39mtoArray(\n\u001b[1;32m   1629\u001b[0m             [_to_java_column(lit(v)) \u001b[38;5;28;01mfor\u001b[39;00m v \u001b[38;5;129;01min\u001b[39;00m (args \u001b[38;5;129;01mor\u001b[39;00m [])]\n\u001b[1;32m   1630\u001b[0m         )\n\u001b[0;32m-> 1631\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m DataFrame(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_jsparkSession\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msql\u001b[49m\u001b[43m(\u001b[49m\u001b[43msqlQuery\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlitArgs\u001b[49m\u001b[43m)\u001b[49m, \u001b[38;5;28mself\u001b[39m)\n\u001b[1;32m   1632\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m   1633\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(kwargs) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/py4j/java_gateway.py:1322\u001b[0m, in \u001b[0;36mJavaMember.__call__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m   1316\u001b[0m command \u001b[38;5;241m=\u001b[39m proto\u001b[38;5;241m.\u001b[39mCALL_COMMAND_NAME \u001b[38;5;241m+\u001b[39m\\\n\u001b[1;32m   1317\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcommand_header \u001b[38;5;241m+\u001b[39m\\\n\u001b[1;32m   1318\u001b[0m     args_command \u001b[38;5;241m+\u001b[39m\\\n\u001b[1;32m   1319\u001b[0m     proto\u001b[38;5;241m.\u001b[39mEND_COMMAND_PART\n\u001b[1;32m   1321\u001b[0m answer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgateway_client\u001b[38;5;241m.\u001b[39msend_command(command)\n\u001b[0;32m-> 1322\u001b[0m return_value \u001b[38;5;241m=\u001b[39m \u001b[43mget_return_value\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1323\u001b[0m \u001b[43m    \u001b[49m\u001b[43manswer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgateway_client\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtarget_id\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1325\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m temp_arg \u001b[38;5;129;01min\u001b[39;00m temp_args:\n\u001b[1;32m   1326\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(temp_arg, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_detach\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/pyspark/errors/exceptions/captured.py:185\u001b[0m, in \u001b[0;36mcapture_sql_exception.<locals>.deco\u001b[0;34m(*a, **kw)\u001b[0m\n\u001b[1;32m    181\u001b[0m converted \u001b[38;5;241m=\u001b[39m convert_exception(e\u001b[38;5;241m.\u001b[39mjava_exception)\n\u001b[1;32m    182\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(converted, UnknownException):\n\u001b[1;32m    183\u001b[0m     \u001b[38;5;66;03m# Hide where the exception came from that shows a non-Pythonic\u001b[39;00m\n\u001b[1;32m    184\u001b[0m     \u001b[38;5;66;03m# JVM exception message.\u001b[39;00m\n\u001b[0;32m--> 185\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m converted \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    186\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    187\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m\n",
      "\u001b[0;31mAnalysisException\u001b[0m: [TABLE_OR_VIEW_NOT_FOUND] The table or view `fact_billing_and_recovery` cannot be found. Verify the spelling and correctness of the schema and catalog.\nIf you did not qualify the name with a schema, verify the current_schema() output, or qualify the name with the correct schema and catalog.\nTo tolerate the error on drop use DROP VIEW IF EXISTS or DROP TABLE IF EXISTS.; line 1 pos 14;\n'Project [*]\n+- 'UnresolvedRelation [fact_billing_and_recovery], [], false\n"
     ]
    }
   ],
   "source": [
    "# Assuming you have already created a DataFrame `fact_billing_and_recovery`\n",
    "fact_billing_and_recovery_df = spark.sql(\"SELECT * FROM fact_billing_and_recovery\")\n",
    "\n",
    "# Writing the DataFrame into Dremio\n",
    "fact_billing_and_recovery_df.writeTo(\"nessie.fact_billing_and_recovery_final1.fact_billing_and_recovery_data_raw\").createOrReplace()\n",
    "\n",
    "print(\"dou piyasi in dremio lesso (fact_table for billing shilling)\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "81b270ec-92a6-4a16-aff4-a6b0ccff5595",
   "metadata": {},
   "outputs": [
    {
     "ename": "AnalysisException",
     "evalue": "[TABLE_OR_VIEW_NOT_FOUND] The table or view `nessie`.`fact_network_and_loss2`.`fact_network_data_raw` cannot be found. Verify the spelling and correctness of the schema and catalog.\nIf you did not qualify the name with a schema, verify the current_schema() output, or qualify the name with the correct schema and catalog.\nTo tolerate the error on drop use DROP VIEW IF EXISTS or DROP TABLE IF EXISTS.;\n'UnresolvedRelation [nessie, fact_network_and_loss2, fact_network_data_raw], [], false\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAnalysisException\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[23], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mspark\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtable\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mnessie.fact_network_and_loss2.fact_network_data_raw\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mshow()\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/pyspark/sql/readwriter.py:484\u001b[0m, in \u001b[0;36mDataFrameReader.table\u001b[0;34m(self, tableName)\u001b[0m\n\u001b[1;32m    450\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mtable\u001b[39m(\u001b[38;5;28mself\u001b[39m, tableName: \u001b[38;5;28mstr\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDataFrame\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m    451\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Returns the specified table as a :class:`DataFrame`.\u001b[39;00m\n\u001b[1;32m    452\u001b[0m \n\u001b[1;32m    453\u001b[0m \u001b[38;5;124;03m    .. versionadded:: 1.4.0\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    482\u001b[0m \u001b[38;5;124;03m    >>> _ = spark.sql(\"DROP TABLE tblA\")\u001b[39;00m\n\u001b[1;32m    483\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 484\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_df(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_jreader\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtable\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtableName\u001b[49m\u001b[43m)\u001b[49m)\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/py4j/java_gateway.py:1322\u001b[0m, in \u001b[0;36mJavaMember.__call__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m   1316\u001b[0m command \u001b[38;5;241m=\u001b[39m proto\u001b[38;5;241m.\u001b[39mCALL_COMMAND_NAME \u001b[38;5;241m+\u001b[39m\\\n\u001b[1;32m   1317\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcommand_header \u001b[38;5;241m+\u001b[39m\\\n\u001b[1;32m   1318\u001b[0m     args_command \u001b[38;5;241m+\u001b[39m\\\n\u001b[1;32m   1319\u001b[0m     proto\u001b[38;5;241m.\u001b[39mEND_COMMAND_PART\n\u001b[1;32m   1321\u001b[0m answer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgateway_client\u001b[38;5;241m.\u001b[39msend_command(command)\n\u001b[0;32m-> 1322\u001b[0m return_value \u001b[38;5;241m=\u001b[39m \u001b[43mget_return_value\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1323\u001b[0m \u001b[43m    \u001b[49m\u001b[43manswer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgateway_client\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtarget_id\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1325\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m temp_arg \u001b[38;5;129;01min\u001b[39;00m temp_args:\n\u001b[1;32m   1326\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(temp_arg, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_detach\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/pyspark/errors/exceptions/captured.py:185\u001b[0m, in \u001b[0;36mcapture_sql_exception.<locals>.deco\u001b[0;34m(*a, **kw)\u001b[0m\n\u001b[1;32m    181\u001b[0m converted \u001b[38;5;241m=\u001b[39m convert_exception(e\u001b[38;5;241m.\u001b[39mjava_exception)\n\u001b[1;32m    182\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(converted, UnknownException):\n\u001b[1;32m    183\u001b[0m     \u001b[38;5;66;03m# Hide where the exception came from that shows a non-Pythonic\u001b[39;00m\n\u001b[1;32m    184\u001b[0m     \u001b[38;5;66;03m# JVM exception message.\u001b[39;00m\n\u001b[0;32m--> 185\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m converted \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    186\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    187\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m\n",
      "\u001b[0;31mAnalysisException\u001b[0m: [TABLE_OR_VIEW_NOT_FOUND] The table or view `nessie`.`fact_network_and_loss2`.`fact_network_data_raw` cannot be found. Verify the spelling and correctness of the schema and catalog.\nIf you did not qualify the name with a schema, verify the current_schema() output, or qualify the name with the correct schema and catalog.\nTo tolerate the error on drop use DROP VIEW IF EXISTS or DROP TABLE IF EXISTS.;\n'UnresolvedRelation [nessie, fact_network_and_loss2, fact_network_data_raw], [], false\n"
     ]
    }
   ],
   "source": [
    "spark.read.table(\"nessie.fact_network_and_loss2.fact_network_data_raw\").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21f0930e-b382-4f8f-bcb0-6fcc72ff16ed",
   "metadata": {},
   "source": [
    "### Appending values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "66871a4e-8d37-4b3e-8d8a-32dfd1344be3",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "12e01bc2-64d0-4833-87c9-6f63b9ca1cbb",
   "metadata": {},
   "outputs": [
    {
     "ename": "AnalysisException",
     "evalue": "[TABLE_OR_VIEW_NOT_FOUND] The table or view `nessie`.`fact_network_and_loss11`.`fact_network_and_loss_data_raw`.`snapshots` cannot be found. Verify the spelling and correctness of the schema and catalog.\nIf you did not qualify the name with a schema, verify the current_schema() output, or qualify the name with the correct schema and catalog.\nTo tolerate the error on drop use DROP VIEW IF EXISTS or DROP TABLE IF EXISTS.; line 3 pos 9;\n'Project [*]\n+- 'UnresolvedRelation [nessie, fact_network_and_loss11, fact_network_and_loss_data_raw, snapshots], [], false\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAnalysisException\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[5], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mspark\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msql\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\"\"\u001b[39;49m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;124;43m    SELECT *\u001b[39;49m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;124;43m    FROM nessie.fact_network_and_loss11.fact_network_and_loss_data_raw.snapshots\u001b[39;49m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;124;43m\"\"\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mshow(truncate\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/pyspark/sql/session.py:1631\u001b[0m, in \u001b[0;36mSparkSession.sql\u001b[0;34m(self, sqlQuery, args, **kwargs)\u001b[0m\n\u001b[1;32m   1627\u001b[0m         \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jvm \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1628\u001b[0m         litArgs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jvm\u001b[38;5;241m.\u001b[39mPythonUtils\u001b[38;5;241m.\u001b[39mtoArray(\n\u001b[1;32m   1629\u001b[0m             [_to_java_column(lit(v)) \u001b[38;5;28;01mfor\u001b[39;00m v \u001b[38;5;129;01min\u001b[39;00m (args \u001b[38;5;129;01mor\u001b[39;00m [])]\n\u001b[1;32m   1630\u001b[0m         )\n\u001b[0;32m-> 1631\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m DataFrame(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_jsparkSession\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msql\u001b[49m\u001b[43m(\u001b[49m\u001b[43msqlQuery\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlitArgs\u001b[49m\u001b[43m)\u001b[49m, \u001b[38;5;28mself\u001b[39m)\n\u001b[1;32m   1632\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m   1633\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(kwargs) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/py4j/java_gateway.py:1322\u001b[0m, in \u001b[0;36mJavaMember.__call__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m   1316\u001b[0m command \u001b[38;5;241m=\u001b[39m proto\u001b[38;5;241m.\u001b[39mCALL_COMMAND_NAME \u001b[38;5;241m+\u001b[39m\\\n\u001b[1;32m   1317\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcommand_header \u001b[38;5;241m+\u001b[39m\\\n\u001b[1;32m   1318\u001b[0m     args_command \u001b[38;5;241m+\u001b[39m\\\n\u001b[1;32m   1319\u001b[0m     proto\u001b[38;5;241m.\u001b[39mEND_COMMAND_PART\n\u001b[1;32m   1321\u001b[0m answer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgateway_client\u001b[38;5;241m.\u001b[39msend_command(command)\n\u001b[0;32m-> 1322\u001b[0m return_value \u001b[38;5;241m=\u001b[39m \u001b[43mget_return_value\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1323\u001b[0m \u001b[43m    \u001b[49m\u001b[43manswer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgateway_client\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtarget_id\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1325\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m temp_arg \u001b[38;5;129;01min\u001b[39;00m temp_args:\n\u001b[1;32m   1326\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(temp_arg, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_detach\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/pyspark/errors/exceptions/captured.py:185\u001b[0m, in \u001b[0;36mcapture_sql_exception.<locals>.deco\u001b[0;34m(*a, **kw)\u001b[0m\n\u001b[1;32m    181\u001b[0m converted \u001b[38;5;241m=\u001b[39m convert_exception(e\u001b[38;5;241m.\u001b[39mjava_exception)\n\u001b[1;32m    182\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(converted, UnknownException):\n\u001b[1;32m    183\u001b[0m     \u001b[38;5;66;03m# Hide where the exception came from that shows a non-Pythonic\u001b[39;00m\n\u001b[1;32m    184\u001b[0m     \u001b[38;5;66;03m# JVM exception message.\u001b[39;00m\n\u001b[0;32m--> 185\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m converted \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    186\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    187\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m\n",
      "\u001b[0;31mAnalysisException\u001b[0m: [TABLE_OR_VIEW_NOT_FOUND] The table or view `nessie`.`fact_network_and_loss11`.`fact_network_and_loss_data_raw`.`snapshots` cannot be found. Verify the spelling and correctness of the schema and catalog.\nIf you did not qualify the name with a schema, verify the current_schema() output, or qualify the name with the correct schema and catalog.\nTo tolerate the error on drop use DROP VIEW IF EXISTS or DROP TABLE IF EXISTS.; line 3 pos 9;\n'Project [*]\n+- 'UnresolvedRelation [nessie, fact_network_and_loss11, fact_network_and_loss_data_raw, snapshots], [], false\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"\"\"\n",
    "    SELECT *\n",
    "    FROM nessie.fact_network_and_loss11.fact_network_and_loss_data_raw.snapshots\n",
    "\"\"\").show(truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed950274-4901-4bfd-b6b6-958e16ec37d3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
