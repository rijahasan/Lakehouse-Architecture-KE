{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "735f7176-9501-4a00-bc3b-b1a40d3bc328",
   "metadata": {},
   "outputs": [],
   "source": [
    "#172.18.0.4\n",
    "import pyspark\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.types import StructType, StructField, IntegerType, StringType, DoubleType\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fcc6434-036c-4246-992c-f4a4ae631018",
   "metadata": {},
   "outputs": [],
   "source": [
    "CATALOG_URI = \"http://nessie:19120/api/v1\"  # Nessie Server URI\n",
    "WAREHOUSE = \"s3://warehouse/\"               # Minio Address to Write to\n",
    "STORAGE_URI = \"http://172.18.0.4:9000\"     # Minio IP address from docker inspect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88d023b3-7907-4832-8383-219fc3ccb10a",
   "metadata": {},
   "outputs": [],
   "source": [
    "conf = (\n",
    "    pyspark.SparkConf()\n",
    "        .setAppName('billing')\n",
    "    \n",
    "    # .set(\"spark.executor.instances\", \"3\")  # 3 Executors\n",
    "    # .set(\"spark.executor.cores\", \"3\")  # 3 Cores per executor\n",
    "    # .set(\"spark.executor.memory\", \"3g\")  # 3GB RAM per executor\n",
    "    # .set(\"spark.driver.memory\", \"4g\")  # Ensure driver has enough memory\n",
    "    # .set(\"spark.sql.shuffle.partitions\", \"200\")  # Tune for large joins\n",
    "    # .set(\"spark.default.parallelism\", \"9\")  # Optimize parallel processing\n",
    "    # .set(\"spark.executor.instances\", \"3\")  # 3 Executors\n",
    "    # .set(\"spark.executor.cores\", \"2\")  # 3 Cores per executor\n",
    "    # .set(\"spark.executor.memory\", \"6g\")  # 3GB RAM per executor\n",
    "    # .set(\"spark.driver.memory\", \"6g\")  # Ensure driver has enough memory\n",
    "    # .set(\"spark.sql.shuffle.partitions\", \"200\")  # Tune for large joins\n",
    "    # .set(\"spark.default.parallelism\", \"200\")  # Optimize parallel processing\n",
    "    # .set(\"spark.memory.fraction\", \"0.7\")  #\n",
    "    # .set(\"spark.executor.memoryOverhead\", \"1024\") \n",
    "#     .set(\"spark.dynamicAllocation.enabled\", \"true\")\n",
    "# .set(\"spark.shuffle.service.enabled\", \"true\")\n",
    "        .set(\"spark.sql.debug.maxToStringFields\", \"100000\")\n",
    "        .set('spark.jars', '/opt/spark/workjars/iceberg-spark-runtime-3.5_2.12-1.5.0.jar,/opt/spark/workjars/nessie-spark-extensions-3.5_2.12-0.77.1.jar,/opt/spark/workjars/bundle-2.24.8.jar,/opt/spark/workjars/url-connection-client-2.24.8.jar')\n",
    "        .set('spark.sql.extensions', 'org.apache.iceberg.spark.extensions.IcebergSparkSessionExtensions,org.projectnessie.spark.extensions.NessieSparkSessionExtensions')\n",
    "        .set('spark.sql.catalog.nessie', 'org.apache.iceberg.spark.SparkCatalog')\n",
    "        .set('spark.sql.catalog.nessie.uri', CATALOG_URI)\n",
    "        .set('spark.sql.catalog.nessie.ref', 'main')\n",
    "        .set('spark.sql.catalog.nessie.authentication.type', 'NONE')\n",
    "        .set('spark.sql.catalog.nessie.catalog-impl', 'org.apache.iceberg.nessie.NessieCatalog')\n",
    "        .set('spark.sql.catalog.nessie.s3.endpoint', STORAGE_URI)\n",
    "        .set('spark.sql.catalog.nessie.warehouse', WAREHOUSE)\n",
    "        .set('spark.sql.catalog.nessie.io-impl', 'org.apache.iceberg.aws.s3.S3FileIO')\n",
    "        .set(\"spark.executor.memory\", \"2g\")\n",
    "        .set(\"spark.driver.memory\", \"2g\")\n",
    "        .set(\"spark.executor.memoryOverhead\", \"512m\")\n",
    "        .set(\"spark.sql.shuffle.partitions\", \"64\")\n",
    "        .set(\"spark.shuffle.spill\", \"true\")\n",
    "        .set(\"spark.shuffle.memoryFraction\", \"0.4\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b867a46-7baf-40ba-b639-cc3e953db0c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark = SparkSession.builder.master(\"local[*]\").config(conf=conf).getOrCreate()\n",
    "print(\"Spark Session Started\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e44d5b7e-896f-4b01-9379-819d6402225a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.clustering import KMeans\n",
    "from pyspark.ml.feature import StringIndexer\n",
    "from pyspark.ml.evaluation import ClusteringEvaluator\n",
    "from pyspark.sql import functions as F\n",
    "\n",
    "# Load the data (assuming you have already loaded it into a DataFrame)\n",
    "df = spark.read.table(\"nessie.ageing.ageing_data_raw\")\n",
    "\n",
    "# Index the \"AccountContract\" column to convert it to a numeric feature\n",
    "indexer = StringIndexer(inputCol=\"AccountContract\", outputCol=\"AccountContractIndex\")\n",
    "indexed_df = indexer.fit(df).transform(df)\n",
    "\n",
    "# Select relevant features for clustering (you can add more columns here if needed)\n",
    "features = indexed_df.select(\"AccountContractIndex\")\n",
    "\n",
    "# Perform KMeans clustering\n",
    "kmeans = KMeans(k=3, seed=1, featuresCol=\"AccountContractIndex\", predictionCol=\"prediction\")\n",
    "model = kmeans.fit(features)\n",
    "\n",
    "# Make predictions\n",
    "predictions = model.transform(features)\n",
    "\n",
    "# Evaluate clustering by computing Silhouette score\n",
    "evaluator = ClusteringEvaluator()\n",
    "\n",
    "silhouette = evaluator.evaluate(predictions)\n",
    "print(f\"Silhouette with squared Euclidean distance = {silhouette}\")\n",
    "\n",
    "# Show the cluster centers\n",
    "centers = model.clusterCenters()\n",
    "print(\"Cluster Centers: \")\n",
    "for center in centers:\n",
    "    print(center)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
