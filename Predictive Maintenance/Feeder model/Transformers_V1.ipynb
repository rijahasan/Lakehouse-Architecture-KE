{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o8LOC_E1QOBq",
        "outputId": "8b8539bd-dce4-44d6-e00d-d528ec23af16"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Using device: cuda\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "<ipython-input-1-353206a3a352>:44: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  cleaned_data[col] = le.fit_transform(cleaned_data[col].astype(str))\n",
            "<ipython-input-1-353206a3a352>:44: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  cleaned_data[col] = le.fit_transform(cleaned_data[col].astype(str))\n",
            "<ipython-input-1-353206a3a352>:44: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  cleaned_data[col] = le.fit_transform(cleaned_data[col].astype(str))\n",
            "<ipython-input-1-353206a3a352>:44: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  cleaned_data[col] = le.fit_transform(cleaned_data[col].astype(str))\n",
            "<ipython-input-1-353206a3a352>:44: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  cleaned_data[col] = le.fit_transform(cleaned_data[col].astype(str))\n",
            "<ipython-input-1-353206a3a352>:44: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  cleaned_data[col] = le.fit_transform(cleaned_data[col].astype(str))\n",
            "<ipython-input-1-353206a3a352>:44: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  cleaned_data[col] = le.fit_transform(cleaned_data[col].astype(str))\n",
            "<ipython-input-1-353206a3a352>:44: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  cleaned_data[col] = le.fit_transform(cleaned_data[col].astype(str))\n",
            "<ipython-input-1-353206a3a352>:44: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  cleaned_data[col] = le.fit_transform(cleaned_data[col].astype(str))\n",
            "<ipython-input-1-353206a3a352>:51: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  cleaned_data[numerical_features] = scaler.fit_transform(cleaned_data[numerical_features])\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import DataLoader, TensorDataset\n",
        "from sklearn.preprocessing import MinMaxScaler, LabelEncoder\n",
        "from sklearn.metrics import precision_score, recall_score, f1_score\n",
        "\n",
        "# Check and Set Device\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(f\"Using device: {device}\")\n",
        "\n",
        "# Load Data\n",
        "cleaned_data = pd.read_csv(\"/content/filtered_fault_data.csv\")\n",
        "cleaned_data = cleaned_data.sort_values(by=\"Createdon\")\n",
        "\n",
        "# Create Lag Features\n",
        "for lag in range(1, 8):  # Last 7 days\n",
        "    cleaned_data[f\"temp_lag_{lag}\"] = cleaned_data[\"temp\"].shift(lag)\n",
        "\n",
        "# Target Variable (Failure in next 7 days)\n",
        "cleaned_data[\"target\"] = cleaned_data.groupby(\"fdr_Id\")[\"fdr_Id\"].transform(lambda x: x.shift(-7).notna().astype(int))\n",
        "\n",
        "# Drop NaN values from shifting\n",
        "cleaned_data = cleaned_data.dropna()\n",
        "\n",
        "# Select Features\n",
        "features = [\n",
        "    \"isemergency\", \"TAT\", \"tempmax\", \"tempmin\", \"temp\", \"dew\", \"humidity\", \"precip\", \"precipprob\", \"precipcover\",\n",
        "    \"snow\", \"snowdepth\", \"windgust\", \"windspeed\", \"winddir\", \"sealevelpressure\", \"cloudcover\", \"visibility\",\n",
        "    \"solarradiation\", \"solarenergy\", \"uvindex\", \"severerisk\"\n",
        "]\n",
        "\n",
        "features += [col for col in cleaned_data.columns if \"lag\" in col or \"rolling\" in col]\n",
        "\n",
        "# Encode Categorical Variables\n",
        "categorical_features = [\"OutageType\", \"outageSubType\", \"initialoffreason\", \"htclosingreason\",\n",
        "                        \"fdr_Id\", \"fdr_name\", \"grid_name\", \"Relay\", \"israintripping\"]\n",
        "\n",
        "label_encoders = {}\n",
        "for col in categorical_features:\n",
        "    le = LabelEncoder()\n",
        "    cleaned_data[col] = le.fit_transform(cleaned_data[col].astype(str))\n",
        "    label_encoders[col] = le\n",
        "    features.append(col)\n",
        "\n",
        "# Normalize Numerical Features\n",
        "numerical_features = [col for col in features if col not in categorical_features]\n",
        "scaler = MinMaxScaler()\n",
        "cleaned_data[numerical_features] = scaler.fit_transform(cleaned_data[numerical_features])\n",
        "\n",
        "# Convert Data to Sequences\n",
        "def create_sequences(df, seq_length=4):\n",
        "    X, y = [], []\n",
        "    for i in range(len(df) - seq_length - 1):\n",
        "        X.append(df[features].iloc[i:i+seq_length].values)\n",
        "        y.append(df[\"target\"].iloc[i+seq_length])\n",
        "    return torch.tensor(X, dtype=torch.float32), torch.tensor(y, dtype=torch.float32)\n",
        "\n",
        "X, y = create_sequences(cleaned_data)\n",
        "\n",
        "# Move Data to GPU\n",
        "X, y = X.to(device), y.to(device)\n",
        "\n",
        "# Train-Test Split\n",
        "split_idx = int(len(X) * 0.8)\n",
        "X_train, X_test = X[:split_idx], X[split_idx:]\n",
        "y_train, y_test = y[:split_idx], y[split_idx:]\n",
        "\n",
        "# DataLoader\n",
        "batch_size = 64\n",
        "train_dataset = TensorDataset(X_train, y_train)\n",
        "test_dataset = TensorDataset(X_test, y_test)\n",
        "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=False)\n",
        "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
        "\n",
        "# Transformer Model\n",
        "class TransformerModel(nn.Module):\n",
        "    def __init__(self, input_dim, num_heads=4, num_layers=3, hidden_dim=128):\n",
        "        super(TransformerModel, self).__init__()\n",
        "        self.embedding = nn.Linear(input_dim, hidden_dim)  # Project input to hidden_dim\n",
        "        self.positional_encoding = nn.Parameter(torch.zeros(1, 50, hidden_dim))  # Learnable positional encoding\n",
        "        encoder_layer = nn.TransformerEncoderLayer(d_model=hidden_dim, nhead=num_heads, dim_feedforward=256)\n",
        "        self.transformer_encoder = nn.TransformerEncoder(encoder_layer, num_layers=num_layers)\n",
        "        self.fc = nn.Linear(hidden_dim, 1)  # Output layer for binary classification\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.embedding(x) + self.positional_encoding[:, :x.size(1), :]\n",
        "        x = self.transformer_encoder(x)\n",
        "        x = x[:, -1, :]  # Use last time step's output\n",
        "        return torch.sigmoid(self.fc(x))\n",
        "\n",
        "# Instantiate Model\n",
        "model = TransformerModel(input_dim=X.shape[2]).to(device)\n",
        "criterion = nn.BCELoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
        "\n",
        "# Train Model\n",
        "for epoch in range(4):\n",
        "    model.train()\n",
        "    total_loss = 0\n",
        "    for batch_X, batch_y in train_loader:\n",
        "        batch_X, batch_y = batch_X.to(device), batch_y.to(device)\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        # Forward pass\n",
        "        output = model(batch_X).squeeze()\n",
        "        loss = criterion(output, batch_y)\n",
        "        total_loss += loss.item()\n",
        "\n",
        "        # Backward pass\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "    print(f\"Epoch {epoch+1}, Loss: {total_loss / len(train_loader):.4f}\")\n",
        "\n",
        "# Evaluate Model\n",
        "model.eval()\n",
        "y_pred_list, y_test_list = [], []\n",
        "\n",
        "with torch.no_grad():\n",
        "    for batch_X, batch_y in test_loader:\n",
        "        batch_X, batch_y = batch_X.to(device), batch_y.to(device)\n",
        "        output = model(batch_X).squeeze()\n",
        "        y_pred_list.extend(output.cpu().numpy())\n",
        "        y_test_list.extend(batch_y.cpu().numpy())\n",
        "\n",
        "# Convert Predictions to Binary\n",
        "y_pred_binary = (np.array(y_pred_list) > 0.5).astype(int)\n",
        "y_test_cpu = np.array(y_test_list)\n",
        "\n",
        "# Compute Metrics\n",
        "precision = precision_score(y_test_cpu, y_pred_binary)\n",
        "recall = recall_score(y_test_cpu, y_pred_binary)\n",
        "f1 = f1_score(y_test_cpu, y_pred_binary)\n",
        "\n",
        "print(f\"Precision: {precision:.4f}, Recall: {recall:.4f}, F1 Score: {f1:.4f}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9iJEMxcstCgI",
        "outputId": "3678aecb-59da-4d8d-eef9-ee122299cc95"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import torch\n",
        "\n",
        "def predict_feeder_failures(model, data, month, features, device=\"cuda\"):\n",
        "    \"\"\"\n",
        "    Predicts which feeders are likely to fail in a given month.\n",
        "\n",
        "    Parameters:\n",
        "        model (torch.nn.Module): Trained Transformer model.\n",
        "        data (pd.DataFrame): Cleaned and preprocessed dataset.\n",
        "        month (str): Target month in 'YYYY-MM' format.\n",
        "        features (list): List of feature column names used in training.\n",
        "        device (str): 'cuda' or 'cpu' depending on availability.\n",
        "\n",
        "    Returns:\n",
        "        List of feeder IDs predicted to fail in the given month.\n",
        "    \"\"\"\n",
        "    # Convert 'Createdon' to datetime format and filter data for the given month\n",
        "    data[\"Createdon\"] = pd.to_datetime(data[\"Createdon\"])\n",
        "    month_data = data[data[\"Createdon\"].dt.strftime(\"%Y-%m\") == month]\n",
        "\n",
        "    if month_data.empty:\n",
        "        print(f\"No data available for {month}.\")\n",
        "        return []\n",
        "\n",
        "    # Ensure feature columns exist\n",
        "    month_data = month_data.dropna(subset=features)\n",
        "\n",
        "    # Convert data into sequences (assuming sequence length = 4)\n",
        "    def create_sequences(df, seq_length=4):\n",
        "        X, fdr_ids = [], []\n",
        "        for i in range(len(df) - seq_length):\n",
        "            X.append(df[features].iloc[i:i+seq_length].values)\n",
        "            fdr_ids.append(df[\"fdr_Id\"].iloc[i + seq_length])  # Capture Feeder ID\n",
        "        return torch.tensor(X, dtype=torch.float32), fdr_ids\n",
        "\n",
        "    X, fdr_ids = create_sequences(month_data)\n",
        "\n",
        "    if len(X) == 0:\n",
        "        print(f\"Not enough sequential data for predictions in {month}.\")\n",
        "        return []\n",
        "\n",
        "    # Move data to device\n",
        "    X = X.to(device)\n",
        "\n",
        "    # Predict using the model\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        predictions = model(X).squeeze().cpu().numpy()\n",
        "\n",
        "    # Convert predictions to binary (threshold > 0.5 means failure)\n",
        "    predicted_failures = (predictions > 0.5).astype(int)\n",
        "\n",
        "    # Get feeder IDs of predicted failures\n",
        "    failed_feeders = [fdr for fdr, pred in zip(fdr_ids, predicted_failures) if pred == 1]\n",
        "\n",
        "    return list(set(failed_feeders))  # Remove duplicates\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ApDOPbOOea_O"
      },
      "outputs": [],
      "source": [
        "month = \"2025-03\"  # Example month\n",
        "failed_feeders = predict_feeder_failures(model, cleaned_data, month, features)\n",
        "print(f\"Feeders predicted to fail in {month}: {failed_feeders}\")"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
