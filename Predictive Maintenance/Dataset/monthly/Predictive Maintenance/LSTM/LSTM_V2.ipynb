{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1mfa_g3z0YFN",
        "outputId": "ecfa46d2-c27b-43dc-ac45-555cdfb7634b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10, Loss: 0.6190\n",
            "Epoch 2/10, Loss: 0.5632\n",
            "Epoch 3/10, Loss: 0.4802\n",
            "Epoch 4/10, Loss: 0.4402\n",
            "Epoch 5/10, Loss: 0.4234\n",
            "Epoch 6/10, Loss: 0.4076\n",
            "Epoch 7/10, Loss: 0.4058\n",
            "Epoch 8/10, Loss: 0.4072\n",
            "Epoch 9/10, Loss: 0.4056\n",
            "Epoch 10/10, Loss: 0.4069\n",
            "Precision: 0.7757, Recall: 0.9326, F1 Score: 0.8469\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import DataLoader, TensorDataset\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from sklearn.metrics import precision_score, recall_score, f1_score\n",
        "\n",
        "# ----- Step 1: Load and Prepare Monthly Data -----\n",
        "df_monthly = pd.read_csv(\"/content/feeder_monthly_data_upto_2024.csv\")\n",
        "df_monthly['Month'] = pd.to_datetime(df_monthly['Month'])\n",
        "df_monthly['Year'] = df_monthly['Month'].dt.year\n",
        "df_monthly['Month_Num'] = df_monthly['Month'].dt.month\n",
        "df_monthly = df_monthly.sort_values(by=['fdr_Id', 'Month'])\n",
        "\n",
        "df_monthly['target'] = df_monthly.groupby('fdr_Id')['Fault_Label'].shift(-1)\n",
        "df_monthly = df_monthly.dropna(subset=['target'])\n",
        "df_monthly['target'] = df_monthly['target'].astype(int)\n",
        "\n",
        "# ----- Step 2: Define Features and Normalize -----\n",
        "exclude_cols = ['fdr_Id', 'Month', 'Fault_Label', 'target']\n",
        "features = [col for col in df_monthly.columns if col not in exclude_cols]\n",
        "scaler = MinMaxScaler()\n",
        "df_monthly[features] = scaler.fit_transform(df_monthly[features])\n",
        "\n",
        "# ----- Step 3: Create Feeder-Wise Sequences -----\n",
        "def create_sequences_by_feeder(df, seq_length=12):\n",
        "    X_list, y_list = [], []\n",
        "    feeders = df['fdr_Id'].unique()\n",
        "    for feeder in feeders:\n",
        "        feeder_df = df[df['fdr_Id'] == feeder].reset_index(drop=True)\n",
        "        for i in range(len(feeder_df) - seq_length):\n",
        "            seq_X = feeder_df[features].iloc[i : i + seq_length].values\n",
        "            seq_y = feeder_df['target'].iloc[i + seq_length]\n",
        "            X_list.append(seq_X)\n",
        "            y_list.append(seq_y)\n",
        "    return torch.tensor(np.array(X_list), dtype=torch.float32), torch.tensor(np.array(y_list), dtype=torch.float32)\n",
        "\n",
        "seq_length = 12\n",
        "X, y = create_sequences_by_feeder(df_monthly, seq_length=seq_length)\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "X, y = X.to(device), y.to(device)\n",
        "\n",
        "# ----- Step 4: Split Data and Create DataLoaders -----\n",
        "split_idx = int(len(X) * 0.8)\n",
        "X_train, X_test = X[:split_idx], X[split_idx:]\n",
        "y_train, y_test = y[:split_idx], y[split_idx:]\n",
        "\n",
        "batch_size = 64\n",
        "train_dataset = TensorDataset(X_train, y_train)\n",
        "test_dataset = TensorDataset(X_test, y_test)\n",
        "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
        "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
        "\n",
        "# ----- Step 5: Define the LSTM Model -----\n",
        "class LSTMModel(nn.Module):\n",
        "    def __init__(self, input_dim, hidden_dim=128, num_layers=2, dropout=0.3):\n",
        "        super(LSTMModel, self).__init__()\n",
        "        self.lstm = nn.LSTM(input_dim, hidden_dim, num_layers=num_layers, batch_first=True, dropout=dropout)\n",
        "        self.fc = nn.Linear(hidden_dim, 1)\n",
        "\n",
        "    def forward(self, x):\n",
        "        _, (hidden, _) = self.lstm(x)\n",
        "        x = hidden[-1]  # Take the last layer's hidden state\n",
        "        x = self.fc(x)\n",
        "        return torch.sigmoid(x)\n",
        "\n",
        "# Instantiate model\n",
        "model = LSTMModel(input_dim=X.shape[2]).to(device)\n",
        "criterion = nn.BCELoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
        "\n",
        "# ----- Step 6: Train the Model -----\n",
        "num_epochs = 10\n",
        "for epoch in range(num_epochs):\n",
        "    model.train()\n",
        "    total_loss = 0\n",
        "    for batch_X, batch_y in train_loader:\n",
        "        optimizer.zero_grad()\n",
        "        output = model(batch_X).squeeze()\n",
        "        loss = criterion(output, batch_y)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        total_loss += loss.item()\n",
        "    print(f\"Epoch {epoch+1}/{num_epochs}, Loss: {total_loss / len(train_loader):.4f}\")\n",
        "\n",
        "# ----- Step 7: Evaluate the Model -----\n",
        "model.eval()\n",
        "y_pred_list, y_test_list = [], []\n",
        "with torch.no_grad():\n",
        "    for batch_X, batch_y in test_loader:\n",
        "        output = model(batch_X).squeeze()\n",
        "        y_pred_list.extend(output.cpu().numpy())\n",
        "        y_test_list.extend(batch_y.cpu().numpy())\n",
        "\n",
        "y_pred_binary = (np.array(y_pred_list) > 0.5).astype(int)\n",
        "y_test_cpu = np.array(y_test_list)\n",
        "\n",
        "precision = precision_score(y_test_cpu, y_pred_binary)\n",
        "recall = recall_score(y_test_cpu, y_pred_binary)\n",
        "f1 = f1_score(y_test_cpu, y_pred_binary)\n",
        "print(f\"Precision: {precision:.4f}, Recall: {recall:.4f}, F1 Score: {f1:.4f}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import DataLoader, TensorDataset\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from sklearn.metrics import precision_score, recall_score, f1_score\n",
        "\n",
        "# ----- Step 1: Load and Prepare Monthly Data -----\n",
        "df_monthly = pd.read_csv(\"/content/feeder_monthly_data_upto_2024.csv\")\n",
        "df_monthly['Month'] = pd.to_datetime(df_monthly['Month'])\n",
        "df_monthly['Year'] = df_monthly['Month'].dt.year\n",
        "df_monthly['Month_Num'] = df_monthly['Month'].dt.month\n",
        "df_monthly = df_monthly.sort_values(by=['fdr_Id', 'Month'])\n",
        "\n",
        "df_monthly['target'] = df_monthly.groupby('fdr_Id')['Fault_Label'].shift(-1)\n",
        "df_monthly = df_monthly.dropna(subset=['target'])\n",
        "df_monthly['target'] = df_monthly['target'].astype(int)\n",
        "\n",
        "# ----- Step 2: Define Features and Normalize -----\n",
        "exclude_cols = ['fdr_Id', 'Month', 'Fault_Label', 'target']\n",
        "features = [col for col in df_monthly.columns if col not in exclude_cols]\n",
        "scaler = MinMaxScaler()\n",
        "df_monthly[features] = scaler.fit_transform(df_monthly[features])\n",
        "\n",
        "# ----- Step 3: Create Feeder-Wise Sequences -----\n",
        "def create_sequences_by_feeder(df, seq_length=12):\n",
        "    X_list, y_list = [], []\n",
        "    feeders = df['fdr_Id'].unique()\n",
        "    for feeder in feeders:\n",
        "        feeder_df = df[df['fdr_Id'] == feeder].reset_index(drop=True)\n",
        "        for i in range(len(feeder_df) - seq_length):\n",
        "            seq_X = feeder_df[features].iloc[i : i + seq_length].values\n",
        "            seq_y = feeder_df['target'].iloc[i + seq_length]\n",
        "            X_list.append(seq_X)\n",
        "            y_list.append(seq_y)\n",
        "    return torch.tensor(np.array(X_list), dtype=torch.float32), torch.tensor(np.array(y_list), dtype=torch.float32)\n",
        "\n",
        "seq_length = 3\n",
        "X, y = create_sequences_by_feeder(df_monthly, seq_length=seq_length)\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "X, y = X.to(device), y.to(device)\n",
        "\n",
        "# ----- Step 4: Split Data and Create DataLoaders -----\n",
        "split_idx = int(len(X) * 0.8)\n",
        "X_train, X_test = X[:split_idx], X[split_idx:]\n",
        "y_train, y_test = y[:split_idx], y[split_idx:]\n",
        "\n",
        "batch_size = 64\n",
        "train_dataset = TensorDataset(X_train, y_train)\n",
        "test_dataset = TensorDataset(X_test, y_test)\n",
        "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
        "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
        "\n",
        "# ----- Step 5: Define the LSTM Model -----\n",
        "class LSTMModel(nn.Module):\n",
        "    def __init__(self, input_dim, hidden_dim=128, num_layers=2, dropout=0.3):\n",
        "        super(LSTMModel, self).__init__()\n",
        "        self.lstm = nn.LSTM(input_dim, hidden_dim, num_layers=num_layers, batch_first=True, dropout=dropout)\n",
        "        self.fc = nn.Linear(hidden_dim, 1)\n",
        "\n",
        "    def forward(self, x):\n",
        "        _, (hidden, _) = self.lstm(x)\n",
        "        x = hidden[-1]  # Take the last layer's hidden state\n",
        "        x = self.fc(x)\n",
        "        return torch.sigmoid(x)\n",
        "\n",
        "# Instantiate model\n",
        "model = LSTMModel(input_dim=X.shape[2]).to(device)\n",
        "criterion = nn.BCELoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
        "\n",
        "# ----- Step 6: Train the Model -----\n",
        "num_epochs = 10\n",
        "for epoch in range(num_epochs):\n",
        "    model.train()\n",
        "    total_loss = 0\n",
        "    for batch_X, batch_y in train_loader:\n",
        "        optimizer.zero_grad()\n",
        "        output = model(batch_X).squeeze()\n",
        "        loss = criterion(output, batch_y)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        total_loss += loss.item()\n",
        "    print(f\"Epoch {epoch+1}/{num_epochs}, Loss: {total_loss / len(train_loader):.4f}\")\n",
        "\n",
        "# ----- Step 7: Evaluate the Model -----\n",
        "model.eval()\n",
        "y_pred_list, y_test_list = [], []\n",
        "with torch.no_grad():\n",
        "    for batch_X, batch_y in test_loader:\n",
        "        output = model(batch_X).squeeze()\n",
        "        y_pred_list.extend(output.cpu().numpy())\n",
        "        y_test_list.extend(batch_y.cpu().numpy())\n",
        "\n",
        "y_pred_binary = (np.array(y_pred_list) > 0.5).astype(int)\n",
        "y_test_cpu = np.array(y_test_list)\n",
        "\n",
        "precision = precision_score(y_test_cpu, y_pred_binary)\n",
        "recall = recall_score(y_test_cpu, y_pred_binary)\n",
        "f1 = f1_score(y_test_cpu, y_pred_binary)\n",
        "print(f\"Precision: {precision:.4f}, Recall: {recall:.4f}, F1 Score: {f1:.4f}\")\n",
        "\n",
        "# ----- Step 8: Predict Feeders Going Down in January 2025 -----\n",
        "target_month = \"2025-01-01\"\n",
        "target_month = pd.to_datetime(target_month)\n",
        "df_filtered = df_monthly[df_monthly['Month'] < target_month]\n",
        "\n",
        "feeder_predictions = []\n",
        "feeders = df_filtered['fdr_Id'].unique()\n",
        "\n",
        "with torch.no_grad():\n",
        "    for feeder in feeders:\n",
        "        feeder_df = df_filtered[df_filtered['fdr_Id'] == feeder].reset_index(drop=True)\n",
        "        if len(feeder_df) >= seq_length:\n",
        "            seq_data = feeder_df[features].iloc[-seq_length:].values\n",
        "            seq_tensor = torch.tensor(seq_data, dtype=torch.float32).unsqueeze(0).to(device)\n",
        "            pred_prob = model(seq_tensor).item()\n",
        "            feeder_predictions.append((feeder, pred_prob))\n",
        "\n",
        "threshold = 0.7\n",
        "down_feeders = {(f, prob) for f, prob in feeder_predictions if prob > threshold}\n",
        "\n",
        "# ----- Step 9: Compare Predictions with Actual Data -----\n",
        "actual_data = pd.read_csv(\"/content/feeder_monthly_data_2025_01.csv\")\n",
        "actual_failures = set(actual_data[actual_data['Fault_Label'] == 1]['fdr_Id'])\n",
        "\n",
        "predicted_failures = {f for f, _ in down_feeders}\n",
        "true_positives = actual_failures & predicted_failures\n",
        "false_negatives = actual_failures - predicted_failures\n",
        "false_positives = predicted_failures - actual_failures\n",
        "\n",
        "precision = len(true_positives) / (len(true_positives) + len(false_positives) + 1e-9)\n",
        "recall = len(true_positives) / (len(true_positives) + len(false_negatives) + 1e-9)\n",
        "f1_score = 2 * (precision * recall) / (precision + recall + 1e-9)\n",
        "\n",
        "print(f\"Correct Predictions: {len(true_positives)}\")\n",
        "print(f\"Missed Failures: {len(false_negatives)}\")\n",
        "print(f\"Incorrect Predictions: {len(false_positives)}\")\n",
        "print(f\"Precision: {precision:.4f}, Recall: {recall:.4f}, F1 Score: {f1_score:.4f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XCb6bohZ10Gm",
        "outputId": "3a3fc8b6-45eb-47b8-844d-9a2c70be2c30"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10, Loss: 0.6173\n",
            "Epoch 2/10, Loss: 0.5077\n",
            "Epoch 3/10, Loss: 0.4575\n",
            "Epoch 4/10, Loss: 0.4325\n",
            "Epoch 5/10, Loss: 0.4260\n",
            "Epoch 6/10, Loss: 0.4157\n",
            "Epoch 7/10, Loss: 0.4125\n",
            "Epoch 8/10, Loss: 0.4218\n",
            "Epoch 9/10, Loss: 0.4035\n",
            "Epoch 10/10, Loss: 0.4068\n",
            "Precision: 0.8099, Recall: 0.8829, F1 Score: 0.8448\n",
            "Feeders predicted to fail in January 2025:\n",
            "Feeder 99: Probability = 0.7236\n",
            "Feeder 102: Probability = 0.8367\n",
            "Feeder 109: Probability = 0.7433\n",
            "Feeder 111: Probability = 0.9779\n",
            "Feeder 117: Probability = 0.9520\n",
            "Feeder 196: Probability = 0.7420\n",
            "Feeder 208: Probability = 0.8636\n",
            "Feeder 214: Probability = 0.9140\n",
            "Feeder 218: Probability = 0.8540\n",
            "Feeder 221: Probability = 0.9184\n",
            "Feeder 222: Probability = 0.8989\n",
            "Feeder 223: Probability = 0.8462\n",
            "Feeder 224: Probability = 0.7479\n",
            "Feeder 316: Probability = 0.8384\n",
            "Feeder 317: Probability = 0.9302\n",
            "Feeder 326: Probability = 0.7804\n",
            "Feeder 328: Probability = 0.8861\n",
            "Feeder 329: Probability = 0.8822\n",
            "Feeder 330: Probability = 0.8441\n",
            "Feeder 334: Probability = 0.8974\n",
            "Feeder 335: Probability = 0.9332\n",
            "Feeder 338: Probability = 0.8114\n",
            "Feeder 340: Probability = 0.8133\n",
            "Feeder 343: Probability = 0.8777\n",
            "Feeder 344: Probability = 0.9665\n",
            "Feeder 347: Probability = 0.7569\n",
            "Feeder 350: Probability = 0.8595\n",
            "Feeder 353: Probability = 0.8815\n",
            "Feeder 540: Probability = 0.7755\n",
            "Feeder 546: Probability = 0.7723\n",
            "Feeder 548: Probability = 0.9827\n",
            "Feeder 550: Probability = 0.9926\n",
            "Feeder 551: Probability = 0.9608\n",
            "Feeder 552: Probability = 0.9258\n",
            "Feeder 554: Probability = 0.9811\n",
            "Feeder 555: Probability = 0.9716\n",
            "Feeder 556: Probability = 0.8894\n",
            "Feeder 558: Probability = 0.9781\n",
            "Feeder 559: Probability = 0.8732\n",
            "Feeder 560: Probability = 0.9304\n",
            "Feeder 563: Probability = 0.8618\n",
            "Feeder 657: Probability = 0.8969\n",
            "Feeder 667: Probability = 0.8297\n",
            "Feeder 779: Probability = 0.9835\n",
            "Feeder 782: Probability = 0.9813\n",
            "Feeder 791: Probability = 0.9060\n",
            "Feeder 795: Probability = 0.9429\n",
            "Feeder 796: Probability = 0.9666\n",
            "Feeder 813: Probability = 0.9871\n",
            "Feeder 818: Probability = 0.9829\n",
            "Feeder 890: Probability = 0.8385\n",
            "Feeder 1198: Probability = 0.9039\n",
            "Feeder 1205: Probability = 0.9544\n",
            "Feeder 1216: Probability = 0.9701\n",
            "Feeder 1264: Probability = 0.8734\n",
            "Feeder 1265: Probability = 0.8715\n",
            "Feeder 1267: Probability = 0.8821\n",
            "Feeder 1269: Probability = 0.8625\n",
            "Feeder 2018: Probability = 0.9604\n",
            "Feeder 2019: Probability = 0.8278\n",
            "Feeder 2021: Probability = 0.9786\n",
            "Feeder 2023: Probability = 0.9817\n",
            "Feeder 2024: Probability = 0.9725\n",
            "Feeder 2030: Probability = 0.9806\n",
            "Feeder 2034: Probability = 0.7052\n",
            "Feeder 2035: Probability = 0.9379\n",
            "Feeder 2047: Probability = 0.9755\n",
            "Feeder 2073: Probability = 0.8707\n",
            "Feeder 2084: Probability = 0.8356\n",
            "Feeder 2094: Probability = 0.9027\n",
            "Feeder 2100: Probability = 0.8664\n",
            "Feeder 2101: Probability = 0.9185\n",
            "Feeder 2113: Probability = 0.9244\n",
            "Feeder 2124: Probability = 0.8355\n",
            "Feeder 2139: Probability = 0.8108\n",
            "Feeder 2156: Probability = 0.7879\n",
            "Feeder 3016: Probability = 0.7525\n",
            "Feeder 3053: Probability = 0.8583\n",
            "Feeder 3107: Probability = 0.9251\n",
            "Feeder 3108: Probability = 0.9156\n",
            "Feeder 3146: Probability = 0.8214\n",
            "Feeder 3168: Probability = 0.9828\n",
            "Feeder 3176: Probability = 0.9111\n",
            "Feeder 3414: Probability = 0.9213\n",
            "Feeder 3459: Probability = 0.9310\n",
            "Feeder 3466: Probability = 0.8407\n",
            "Feeder 3502: Probability = 0.9861\n",
            "Feeder 3514: Probability = 0.7650\n",
            "Feeder 3539: Probability = 0.9293\n",
            "Feeder 3547: Probability = 0.9831\n",
            "Feeder 3548: Probability = 0.8091\n",
            "Feeder 3549: Probability = 0.9543\n",
            "Feeder 3566: Probability = 0.9183\n",
            "Feeder 3582: Probability = 0.8183\n",
            "Feeder 3596: Probability = 0.8828\n",
            "Feeder 3697: Probability = 0.9426\n",
            "Feeder 3905: Probability = 0.9582\n",
            "Feeder 3957: Probability = 0.7004\n",
            "Predictions saved as 'feeder_predictions_2025_01.csv'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import torch\n",
        "\n",
        "# Set device\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "# ----- Step 1: Load the Processed Monthly Data -----\n",
        "df_monthly = pd.read_csv(\"/content/feeder_monthly_data_upto_2024.csv\")\n",
        "\n",
        "# Convert 'Month' to datetime and extract time features\n",
        "df_monthly['Month'] = pd.to_datetime(df_monthly['Month'])\n",
        "df_monthly['Year'] = df_monthly['Month'].dt.year\n",
        "df_monthly['Month_Num'] = df_monthly['Month'].dt.month\n",
        "\n",
        "# Sort by feeder and Month\n",
        "df_monthly = df_monthly.sort_values(by=['fdr_Id', 'Month'])\n",
        "\n",
        "# ----- Step 2: Define the Feature Set -----\n",
        "exclude_cols = ['fdr_Id', 'Month', 'Fault_Label', 'target']\n",
        "features = [col for col in df_monthly.columns if col not in exclude_cols]\n",
        "print(\"Features used for prediction:\", features)\n",
        "\n",
        "# Load trained model\n",
        "# Ensure the model is loaded and set to evaluation mode\n",
        "model.eval()\n",
        "\n",
        "# ----- Step 3: Define the Sequence Length -----\n",
        "seq_length = 12  # Use past 12 months to predict the target month\n",
        "\n",
        "# ----- Step 4: Select the Target Month -----\n",
        "target_month = \"2025-01-01\"  # Change this to any future date\n",
        "target_month = pd.to_datetime(target_month)\n",
        "\n",
        "# Filter data to only include months before the target month\n",
        "df_filtered = df_monthly[df_monthly['Month'] < target_month]\n",
        "\n",
        "# ----- Step 5: Create Predictions for Each Feeder -----\n",
        "feeder_predictions = []\n",
        "feeders = df_filtered['fdr_Id'].unique()\n",
        "\n",
        "with torch.no_grad():\n",
        "    for feeder in feeders:\n",
        "        feeder_df = df_filtered[df_filtered['fdr_Id'] == feeder].reset_index(drop=True)\n",
        "\n",
        "        # Check if we have enough historical data\n",
        "        if len(feeder_df) >= seq_length:\n",
        "            # Take the last 'seq_length' rows to form the sequence\n",
        "            seq_data = feeder_df[features].iloc[-seq_length:].values\n",
        "            seq_tensor = torch.tensor(seq_data, dtype=torch.float32).unsqueeze(0).to(device)\n",
        "\n",
        "            # Get the prediction probability\n",
        "            pred_prob = model(seq_tensor).item()\n",
        "            feeder_predictions.append((feeder, pred_prob))\n",
        "        else:\n",
        "            print(f\"Not enough data for feeder {feeder}\")\n",
        "\n",
        "# ----- Step 6: Filter Feeders Predicted to Go Down -----\n",
        "threshold = 0.5  # Define fault threshold\n",
        "down_feeders = [(f, prob) for f, prob in feeder_predictions if prob > threshold]\n",
        "\n",
        "# ----- Step 7: Display the Predictions -----\n",
        "print(f\"Feeders predicted to fail in {target_month.strftime('%B %Y')}:\")\n",
        "for f, prob in down_feeders:\n",
        "    print(f\"Feeder {f}: Probability = {prob:.4f}\")\n",
        "\n",
        "# Optionally, save predictions to a CSV\n",
        "pred_df = pd.DataFrame(feeder_predictions, columns=[\"fdr_Id\", \"predicted_probability\"])\n",
        "pred_df.to_csv(f\"feeder_predictions_{target_month.strftime('%Y_%m')}.csv\", index=False)\n",
        "print(f\"Predictions saved as 'feeder_predictions_{target_month.strftime('%Y_%m')}.csv'\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 393
        },
        "id": "S3UxuLaQ_0wz",
        "outputId": "5cc2c05f-fa41-4821-cc4f-19fd8451135c"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Features used for prediction: ['Fault_Count', 'Total_Duration', 'NoFault_Count', 'temp', 'humidity', 'dew', 'windspeed', 'windgust', 'sealevelpressure', 'solarradiation', 'precip', 'reason_Bird / Animal Electrocuted', 'reason_Breaker Fault', 'reason_Bus Bar Broken', 'reason_Cable End Damage', 'reason_Cambric Lead', 'reason_Consumer Side Fault', 'reason_D/O Faulty', 'reason_Fire/Flash/Sparking', 'reason_HT Cable Lead', 'reason_HT IPC', 'reason_HT Jumper', 'reason_Insulator Damage', 'reason_KS Faults', 'reason_LBS Faults', 'reason_LT ABC Broken', 'reason_LT Cable Lead', 'reason_LT DB Fault', 'reason_LT Panel fault', 'reason_LT Wire Broken', 'reason_MISC', 'reason_Misc.', 'reason_PMT Link', 'reason_Relay Fault', 'reason_Tree Snapping', 'reason_Trolley Issue', 'reason_VIR / Wire / Cloth etc Grounding', 'reason_VIR / Wire / Cloth etc. grounding', 'Year', 'Month_Num']\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "The size of tensor a (12) must match the size of tensor b (3) at non-singleton dimension 1",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-9-b307b8b7f858>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     51\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     52\u001b[0m             \u001b[0;31m# Get the prediction probability\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 53\u001b[0;31m             \u001b[0mpred_prob\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mseq_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     54\u001b[0m             \u001b[0mfeeder_predictions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeeder\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpred_prob\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     55\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1734\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1735\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1736\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1737\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1738\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1745\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1746\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1747\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1748\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1749\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-1-462d6dc547bf>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     97\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     98\u001b[0m         \u001b[0;31m# x: (batch_size, seq_length, input_dim)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 99\u001b[0;31m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0membedding\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpositional_encoding\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    100\u001b[0m         \u001b[0;31m# Transformer expects input shape: (seq_length, batch_size, hidden_dim)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    101\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransformer_encoder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtranspose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: The size of tensor a (12) must match the size of tensor b (3) at non-singleton dimension 1"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import torch\n",
        "\n",
        "# Load the trained LSTM model\n",
        "model.eval()\n",
        "\n",
        "def predict_feeder_failures(df, seq_length=12):\n",
        "    feeders = df['fdr_Id'].unique()\n",
        "    predictions = []\n",
        "    with torch.no_grad():\n",
        "        for feeder in feeders:\n",
        "            feeder_df = df[df['fdr_Id'] == feeder].reset_index(drop=True)\n",
        "            if len(feeder_df) >= seq_length:\n",
        "                seq_X = feeder_df[features].iloc[-seq_length:].values\n",
        "                seq_tensor = torch.tensor(seq_X, dtype=torch.float32).unsqueeze(0).to(device)\n",
        "                pred_prob = model(seq_tensor).item()\n",
        "                predictions.append((feeder, pred_prob))\n",
        "    return predictions\n",
        "\n",
        "# Load monthly data and filter for past months\n",
        "df_monthly = pd.read_csv(\"/content/feeder_monthly_data_upto_2024.csv\")\n",
        "df_monthly['Month'] = pd.to_datetime(df_monthly['Month'])\n",
        "target_month = \"2025-01-01\"\n",
        "df_filtered = df_monthly[df_monthly['Month'] < target_month]\n",
        "\n",
        "# Get predictions\n",
        "feeder_predictions = predict_feeder_failures(df_filtered)\n",
        "\n",
        "# Apply threshold\n",
        "threshold = 0.5\n",
        "down_feeders = [(f, prob) for f, prob in feeder_predictions if prob > threshold]\n",
        "\n",
        "# Save predictions\n",
        "pred_df = pd.DataFrame(down_feeders, columns=[\"fdr_Id\", \"predicted_probability\"])\n",
        "pred_df.to_csv(f\"LSTM_predictions_{target_month[:7]}.csv\", index=False)\n",
        "\n",
        "# ----- Compare Predictions with Actual Data -----\n",
        "actual_data = pd.read_csv(\"/content/feeder_monthly_data_2025_01.csv\")\n",
        "actual_data = actual_data[actual_data['Fault_Label'] == 1]\n",
        "actual_feeders = set(actual_data['fdr_Id'])\n",
        "predicted_feeders = set(pred_df['fdr_Id'])\n",
        "\n",
        "# True Positives (Correct Predictions)\n",
        "true_positives = actual_feeders & predicted_feeders\n",
        "\n",
        "# False Negatives (Missed Failures)\n",
        "false_negatives = actual_feeders - predicted_feeders\n",
        "\n",
        "# False Positives (Incorrect Predictions)\n",
        "false_positives = predicted_feeders - actual_feeders\n",
        "\n",
        "# Print Results\n",
        "print(f\"Correct Predictions: {len(true_positives)}\")\n",
        "print(f\"Missed Failures: {len(false_negatives)}\")\n",
        "print(f\"Incorrect Predictions: {len(false_positives)}\")\n",
        "\n",
        "# Save Comparison Results\n",
        "comparison_results = {\n",
        "    \"True Positives\": list(true_positives),\n",
        "    \"False Negatives\": list(false_negatives),\n",
        "    \"False Positives\": list(false_positives),\n",
        "}\n",
        "pd.DataFrame(dict([(k, pd.Series(v)) for k, v in comparison_results.items()])).to_csv(\"prediction_comparison.csv\", index=False)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 332
        },
        "id": "EImFIoG5FcDq",
        "outputId": "34d4924f-7dec-4e62-85a5-fedfeb9261da"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'seq_X' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-20-dad4fcbacb54>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[0;31m# Get predictions\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 28\u001b[0;31m \u001b[0mfeeder_predictions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpredict_feeder_failures\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf_filtered\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     29\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[0;31m# Apply threshold\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-20-dad4fcbacb54>\u001b[0m in \u001b[0;36mpredict_feeder_failures\u001b[0;34m(df, seq_length)\u001b[0m\n\u001b[1;32m     14\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeeder_df\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>=\u001b[0m \u001b[0mseq_length\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m                 \u001b[0mseq_tensor\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mseq_X\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat32\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munsqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m                 \u001b[0mpred_prob\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mseq_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m                 \u001b[0mpredictions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeeder\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpred_prob\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'seq_X' is not defined"
          ]
        }
      ]
    }
  ]
}