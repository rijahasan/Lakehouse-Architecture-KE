{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import DataLoader, TensorDataset\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from sklearn.metrics import precision_score, recall_score, f1_score\n",
        "\n",
        "# ----- Step 1: Load and Prepare Weekly Data -----\n",
        "df_weekly = pd.read_csv(\"/content/weekly_train.csv\")\n",
        "df_weekly['Week'] = pd.to_datetime(df_weekly['week'])  # Convert 'week' column to datetime\n",
        "df_weekly = df_weekly.sort_values(by=['fdr_Id', 'Week'])\n",
        "\n",
        "# Shift the Fault_Occurred column to create target labels\n",
        "df_weekly['target'] = df_weekly.groupby('fdr_Id')['Fault_Occurred'].shift(-1)\n",
        "df_weekly = df_weekly.dropna(subset=['target'])\n",
        "df_weekly['target'] = df_weekly['target'].astype(int)\n",
        "\n",
        "# ----- Step 2: Define Features and Normalize -----\n",
        "exclude_cols = ['fdr_Id', 'Week', 'Fault_Occurred', 'target', 'week']\n",
        "features = [col for col in df_weekly.columns if col not in exclude_cols]\n",
        "scaler = MinMaxScaler()\n",
        "df_weekly[features] = scaler.fit_transform(df_weekly[features])\n",
        "\n",
        "# ----- Step 3: Create Feeder-Wise Sequences -----\n",
        "def create_sequences_by_feeder(df, seq_length=3):\n",
        "    X_list, y_list = [], []\n",
        "    feeders = df['fdr_Id'].unique()\n",
        "    for feeder in feeders:\n",
        "        feeder_df = df[df['fdr_Id'] == feeder].reset_index(drop=True)\n",
        "        for i in range(len(feeder_df) - seq_length):\n",
        "            seq_X = feeder_df[features].iloc[i:i+seq_length].values\n",
        "            seq_y = feeder_df['target'].iloc[i + seq_length]\n",
        "            X_list.append(seq_X)\n",
        "            y_list.append(seq_y)\n",
        "    return torch.tensor(np.array(X_list), dtype=torch.float32), torch.tensor(np.array(y_list), dtype=torch.float32)\n",
        "\n",
        "seq_length = 10\n",
        "X, y = create_sequences_by_feeder(df_weekly, seq_length=seq_length)\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "X, y = X.to(device), y.to(device)\n",
        "\n",
        "# ----- Step 4: Split Data and Create DataLoaders -----\n",
        "split_idx = int(len(X) * 0.8)\n",
        "X_train, X_test = X[:split_idx], X[split_idx:]\n",
        "y_train, y_test = y[:split_idx], y[split_idx:]\n",
        "\n",
        "batch_size = 64\n",
        "train_loader = DataLoader(TensorDataset(X_train, y_train), batch_size=batch_size, shuffle=True)\n",
        "test_loader = DataLoader(TensorDataset(X_test, y_test), batch_size=batch_size, shuffle=False)\n",
        "\n",
        "# ----- Step 5: Define the LSTM Model -----\n",
        "class LSTMModel(nn.Module):\n",
        "    def __init__(self, input_dim, hidden_dim=128, num_layers=2, dropout=0.3):\n",
        "        super(LSTMModel, self).__init__()\n",
        "        self.lstm = nn.LSTM(input_dim, hidden_dim, num_layers=num_layers, batch_first=True, dropout=dropout)\n",
        "        self.fc = nn.Linear(hidden_dim, 1)\n",
        "\n",
        "    def forward(self, x):\n",
        "        _, (hidden, _) = self.lstm(x)\n",
        "        x = hidden[-1]\n",
        "        x = self.fc(x)\n",
        "        return torch.sigmoid(x)\n",
        "\n",
        "# Instantiate model\n",
        "model = LSTMModel(input_dim=X.shape[2]).to(device)\n",
        "criterion = nn.BCELoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
        "\n",
        "# ----- Step 6: Train the Model -----\n",
        "num_epochs = 10\n",
        "for epoch in range(num_epochs):\n",
        "    model.train()\n",
        "    total_loss = 0\n",
        "    for batch_X, batch_y in train_loader:\n",
        "        optimizer.zero_grad()\n",
        "        output = model(batch_X).squeeze()\n",
        "        loss = criterion(output, batch_y)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        total_loss += loss.item()\n",
        "    print(f\"Epoch {epoch+1}/{num_epochs}, Loss: {total_loss / len(train_loader):.4f}\")\n",
        "\n",
        "# ----- Step 7: Evaluate the Model -----\n",
        "model.eval()\n",
        "y_pred_list, y_test_list = [], []\n",
        "with torch.no_grad():\n",
        "    for batch_X, batch_y in test_loader:\n",
        "        output = model(batch_X).squeeze()\n",
        "        y_pred_list.extend(output.cpu().numpy())\n",
        "        y_test_list.extend(batch_y.cpu().numpy())\n",
        "\n",
        "y_pred_binary = (np.array(y_pred_list) > 0.5).astype(int)\n",
        "y_test_cpu = np.array(y_test_list)\n",
        "\n",
        "precision = precision_score(y_test_cpu, y_pred_binary)\n",
        "recall = recall_score(y_test_cpu, y_pred_binary)\n",
        "f1 = f1_score(y_test_cpu, y_pred_binary)\n",
        "print(f\"Precision: {precision:.4f}, Recall: {recall:.4f}, F1 Score: {f1:.4f}\")\n",
        "\n",
        "# ----- Step 8: Predict Feeders Going Down in Target Week -----\n",
        "target_week = pd.to_datetime(\"2025-01-06\")\n",
        "df_filtered = df_weekly[df_weekly['Week'] < target_week]\n",
        "\n",
        "feeder_predictions = []\n",
        "feeders = df_filtered['fdr_Id'].unique()\n",
        "\n",
        "with torch.no_grad():\n",
        "    for feeder in feeders:\n",
        "        feeder_df = df_filtered[df_filtered['fdr_Id'] == feeder].reset_index(drop=True)\n",
        "        if len(feeder_df) >= seq_length:\n",
        "            seq_data = feeder_df[features].iloc[-seq_length:].values\n",
        "            seq_tensor = torch.tensor(seq_data, dtype=torch.float32).unsqueeze(0).to(device)\n",
        "            pred_prob = model(seq_tensor).item()\n",
        "            feeder_predictions.append((feeder, pred_prob))\n",
        "\n",
        "threshold = 0.3\n",
        "down_feeders = {(f, prob) for f, prob in feeder_predictions if prob > threshold}\n",
        "\n",
        "# ----- Step 9: Compare Predictions with Actual Data -----\n",
        "actual_data = pd.read_csv(\"/content/weekly_test.csv\")\n",
        "actual_data['Week'] = pd.to_datetime(actual_data['week'])\n",
        "actual_failures = set(actual_data[actual_data['Fault_Occurred'] == 1]['fdr_Id'])\n",
        "\n",
        "predicted_failures = {f for f, _ in down_feeders}\n",
        "true_positives = actual_failures & predicted_failures\n",
        "false_negatives = actual_failures - predicted_failures\n",
        "false_positives = predicted_failures - actual_failures\n",
        "\n",
        "precision = len(true_positives) / (len(true_positives) + len(false_positives) + 1e-9)\n",
        "recall = len(true_positives) / (len(true_positives) + len(false_negatives) + 1e-9)\n",
        "f1_score = 2 * (precision * recall) / (precision + recall + 1e-9)\n",
        "\n",
        "print(f\"Correct Predictions: {len(true_positives)}\")\n",
        "print(f\"Missed Failures: {len(false_negatives)}\")\n",
        "print(f\"Incorrect Predictions: {len(false_positives)}\")\n",
        "print(f\"Precision: {precision:.4f}, Recall: {recall:.4f}, F1 Score: {f1_score:.4f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XCb6bohZ10Gm",
        "outputId": "22b193ba-5b2f-4fae-f471-ca396a6bd187"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10, Loss: 0.6151\n",
            "Epoch 2/10, Loss: 0.5717\n",
            "Epoch 3/10, Loss: 0.5628\n",
            "Epoch 4/10, Loss: 0.5613\n",
            "Epoch 5/10, Loss: 0.5576\n",
            "Epoch 6/10, Loss: 0.5564\n",
            "Epoch 7/10, Loss: 0.5534\n",
            "Epoch 8/10, Loss: 0.5553\n",
            "Epoch 9/10, Loss: 0.5534\n",
            "Epoch 10/10, Loss: 0.5540\n",
            "Precision: 0.6019, Recall: 0.5004, F1 Score: 0.5465\n",
            "Correct Predictions: 78\n",
            "Missed Failures: 51\n",
            "Incorrect Predictions: 7\n",
            "Precision: 0.9176, Recall: 0.6047, F1 Score: 0.7290\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import torch\n",
        "\n",
        "# Set device\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "# ----- Step 1: Load the Processed Monthly Data -----\n",
        "df_monthly = pd.read_csv(\"/content/feeder_monthly_data_upto_2024.csv\")\n",
        "\n",
        "# Convert 'Month' to datetime and extract time features\n",
        "df_monthly['Month'] = pd.to_datetime(df_monthly['Month'])\n",
        "df_monthly['Year'] = df_monthly['Month'].dt.year\n",
        "df_monthly['Month_Num'] = df_monthly['Month'].dt.month\n",
        "\n",
        "# Sort by feeder and Month\n",
        "df_monthly = df_monthly.sort_values(by=['fdr_Id', 'Month'])\n",
        "\n",
        "# ----- Step 2: Define the Feature Set -----\n",
        "exclude_cols = ['fdr_Id', 'Month', 'Fault_Label', 'target']\n",
        "features = [col for col in df_monthly.columns if col not in exclude_cols]\n",
        "print(\"Features used for prediction:\", features)\n",
        "\n",
        "# Load trained model\n",
        "# Ensure the model is loaded and set to evaluation mode\n",
        "model.eval()\n",
        "\n",
        "# ----- Step 3: Define the Sequence Length -----\n",
        "seq_length = 12  # Use past 12 months to predict the target month\n",
        "\n",
        "# ----- Step 4: Select the Target Month -----\n",
        "target_month = \"2025-01-01\"  # Change this to any future date\n",
        "target_month = pd.to_datetime(target_month)\n",
        "\n",
        "# Filter data to only include months before the target month\n",
        "df_filtered = df_monthly[df_monthly['Month'] < target_month]\n",
        "\n",
        "# ----- Step 5: Create Predictions for Each Feeder -----\n",
        "feeder_predictions = []\n",
        "feeders = df_filtered['fdr_Id'].unique()\n",
        "\n",
        "with torch.no_grad():\n",
        "    for feeder in feeders:\n",
        "        feeder_df = df_filtered[df_filtered['fdr_Id'] == feeder].reset_index(drop=True)\n",
        "\n",
        "        # Check if we have enough historical data\n",
        "        if len(feeder_df) >= seq_length:\n",
        "            # Take the last 'seq_length' rows to form the sequence\n",
        "            seq_data = feeder_df[features].iloc[-seq_length:].values\n",
        "            seq_tensor = torch.tensor(seq_data, dtype=torch.float32).unsqueeze(0).to(device)\n",
        "\n",
        "            # Get the prediction probability\n",
        "            pred_prob = model(seq_tensor).item()\n",
        "            feeder_predictions.append((feeder, pred_prob))\n",
        "        else:\n",
        "            print(f\"Not enough data for feeder {feeder}\")\n",
        "\n",
        "# ----- Step 6: Filter Feeders Predicted to Go Down -----\n",
        "threshold = 0.5  # Define fault threshold\n",
        "down_feeders = [(f, prob) for f, prob in feeder_predictions if prob > threshold]\n",
        "\n",
        "# ----- Step 7: Display the Predictions -----\n",
        "print(f\"Feeders predicted to fail in {target_month.strftime('%B %Y')}:\")\n",
        "for f, prob in down_feeders:\n",
        "    print(f\"Feeder {f}: Probability = {prob:.4f}\")\n",
        "\n",
        "# Optionally, save predictions to a CSV\n",
        "pred_df = pd.DataFrame(feeder_predictions, columns=[\"fdr_Id\", \"predicted_probability\"])\n",
        "pred_df.to_csv(f\"feeder_predictions_{target_month.strftime('%Y_%m')}.csv\", index=False)\n",
        "print(f\"Predictions saved as 'feeder_predictions_{target_month.strftime('%Y_%m')}.csv'\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 393
        },
        "id": "S3UxuLaQ_0wz",
        "outputId": "5cc2c05f-fa41-4821-cc4f-19fd8451135c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Features used for prediction: ['Fault_Count', 'Total_Duration', 'NoFault_Count', 'temp', 'humidity', 'dew', 'windspeed', 'windgust', 'sealevelpressure', 'solarradiation', 'precip', 'reason_Bird / Animal Electrocuted', 'reason_Breaker Fault', 'reason_Bus Bar Broken', 'reason_Cable End Damage', 'reason_Cambric Lead', 'reason_Consumer Side Fault', 'reason_D/O Faulty', 'reason_Fire/Flash/Sparking', 'reason_HT Cable Lead', 'reason_HT IPC', 'reason_HT Jumper', 'reason_Insulator Damage', 'reason_KS Faults', 'reason_LBS Faults', 'reason_LT ABC Broken', 'reason_LT Cable Lead', 'reason_LT DB Fault', 'reason_LT Panel fault', 'reason_LT Wire Broken', 'reason_MISC', 'reason_Misc.', 'reason_PMT Link', 'reason_Relay Fault', 'reason_Tree Snapping', 'reason_Trolley Issue', 'reason_VIR / Wire / Cloth etc Grounding', 'reason_VIR / Wire / Cloth etc. grounding', 'Year', 'Month_Num']\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "The size of tensor a (12) must match the size of tensor b (3) at non-singleton dimension 1",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-9-b307b8b7f858>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     51\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     52\u001b[0m             \u001b[0;31m# Get the prediction probability\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 53\u001b[0;31m             \u001b[0mpred_prob\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mseq_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     54\u001b[0m             \u001b[0mfeeder_predictions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeeder\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpred_prob\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     55\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1734\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1735\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1736\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1737\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1738\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1745\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1746\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1747\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1748\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1749\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-1-462d6dc547bf>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     97\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     98\u001b[0m         \u001b[0;31m# x: (batch_size, seq_length, input_dim)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 99\u001b[0;31m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0membedding\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpositional_encoding\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    100\u001b[0m         \u001b[0;31m# Transformer expects input shape: (seq_length, batch_size, hidden_dim)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    101\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransformer_encoder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtranspose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: The size of tensor a (12) must match the size of tensor b (3) at non-singleton dimension 1"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import torch\n",
        "\n",
        "# Load the trained LSTM model\n",
        "model.eval()\n",
        "\n",
        "def predict_feeder_failures(df, seq_length=12):\n",
        "    feeders = df['fdr_Id'].unique()\n",
        "    predictions = []\n",
        "    with torch.no_grad():\n",
        "        for feeder in feeders:\n",
        "            feeder_df = df[df['fdr_Id'] == feeder].reset_index(drop=True)\n",
        "            if len(feeder_df) >= seq_length:\n",
        "                seq_X = feeder_df[features].iloc[-seq_length:].values\n",
        "                seq_tensor = torch.tensor(seq_X, dtype=torch.float32).unsqueeze(0).to(device)\n",
        "                pred_prob = model(seq_tensor).item()\n",
        "                predictions.append((feeder, pred_prob))\n",
        "    return predictions\n",
        "\n",
        "# Load monthly data and filter for past months\n",
        "df_monthly = pd.read_csv(\"/content/feeder_monthly_data_upto_2024.csv\")\n",
        "df_monthly['Month'] = pd.to_datetime(df_monthly['Month'])\n",
        "target_month = \"2025-01-01\"\n",
        "df_filtered = df_monthly[df_monthly['Month'] < target_month]\n",
        "\n",
        "# Get predictions\n",
        "feeder_predictions = predict_feeder_failures(df_filtered)\n",
        "\n",
        "# Apply threshold\n",
        "threshold = 0.5\n",
        "down_feeders = [(f, prob) for f, prob in feeder_predictions if prob > threshold]\n",
        "\n",
        "# Save predictions\n",
        "pred_df = pd.DataFrame(down_feeders, columns=[\"fdr_Id\", \"predicted_probability\"])\n",
        "pred_df.to_csv(f\"LSTM_predictions_{target_month[:7]}.csv\", index=False)\n",
        "\n",
        "# ----- Compare Predictions with Actual Data -----\n",
        "actual_data = pd.read_csv(\"/content/feeder_monthly_data_2025_01.csv\")\n",
        "actual_data = actual_data[actual_data['Fault_Label'] == 1]\n",
        "actual_feeders = set(actual_data['fdr_Id'])\n",
        "predicted_feeders = set(pred_df['fdr_Id'])\n",
        "\n",
        "# True Positives (Correct Predictions)\n",
        "true_positives = actual_feeders & predicted_feeders\n",
        "\n",
        "# False Negatives (Missed Failures)\n",
        "false_negatives = actual_feeders - predicted_feeders\n",
        "\n",
        "# False Positives (Incorrect Predictions)\n",
        "false_positives = predicted_feeders - actual_feeders\n",
        "\n",
        "# Print Results\n",
        "print(f\"Correct Predictions: {len(true_positives)}\")\n",
        "print(f\"Missed Failures: {len(false_negatives)}\")\n",
        "print(f\"Incorrect Predictions: {len(false_positives)}\")\n",
        "\n",
        "# Save Comparison Results\n",
        "comparison_results = {\n",
        "    \"True Positives\": list(true_positives),\n",
        "    \"False Negatives\": list(false_negatives),\n",
        "    \"False Positives\": list(false_positives),\n",
        "}\n",
        "pd.DataFrame(dict([(k, pd.Series(v)) for k, v in comparison_results.items()])).to_csv(\"prediction_comparison.csv\", index=False)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 332
        },
        "id": "EImFIoG5FcDq",
        "outputId": "34d4924f-7dec-4e62-85a5-fedfeb9261da"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'seq_X' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-20-dad4fcbacb54>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[0;31m# Get predictions\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 28\u001b[0;31m \u001b[0mfeeder_predictions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpredict_feeder_failures\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf_filtered\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     29\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[0;31m# Apply threshold\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-20-dad4fcbacb54>\u001b[0m in \u001b[0;36mpredict_feeder_failures\u001b[0;34m(df, seq_length)\u001b[0m\n\u001b[1;32m     14\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeeder_df\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>=\u001b[0m \u001b[0mseq_length\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m                 \u001b[0mseq_tensor\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mseq_X\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat32\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munsqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m                 \u001b[0mpred_prob\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mseq_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m                 \u001b[0mpredictions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeeder\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpred_prob\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'seq_X' is not defined"
          ]
        }
      ]
    }
  ]
}